{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import pprint\n",
    "from utilz import get_top_cat\n",
    "\n",
    "dev_path = 'preds/prediction-matrix-fasttext.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweetid', 'text', 'y_true', 'y_pred', 'a', 'c', 'm', 'u'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(dev_path)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>text</th>\n",
       "      <th>y_true</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "      <th>m</th>\n",
       "      <th>u</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201409307167862784</td>\n",
       "      <td>can somebody tell me what morphine is for ?</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.994950</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200007750383738885</td>\n",
       "      <td>&lt;number&gt; mg . &lt;number&gt; of my x &lt;number&gt; i feee...</td>\n",
       "      <td>m</td>\n",
       "      <td>c</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.085109</td>\n",
       "      <td>0.039649</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1199244035006902272</td>\n",
       "      <td>oh hello crippling anxiety , let ’ s drive hom...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.977033</td>\n",
       "      <td>0.300756</td>\n",
       "      <td>0.001255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1199782125609902084</td>\n",
       "      <td>pop a adderall we gone fuck all night</td>\n",
       "      <td>m</td>\n",
       "      <td>a</td>\n",
       "      <td>0.999206</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.132974</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1199783941764517889</td>\n",
       "      <td>fake exercise facts a xanax a day keeps the tr...</td>\n",
       "      <td>m</td>\n",
       "      <td>m</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.939923</td>\n",
       "      <td>0.974053</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                                               text  \\\n",
       "0  1201409307167862784        can somebody tell me what morphine is for ?   \n",
       "1  1200007750383738885  <number> mg . <number> of my x <number> i feee...   \n",
       "2  1199244035006902272  oh hello crippling anxiety , let ’ s drive hom...   \n",
       "3  1199782125609902084              pop a adderall we gone fuck all night   \n",
       "4  1199783941764517889  fake exercise facts a xanax a day keeps the tr...   \n",
       "\n",
       "  y_true y_pred         a         c         m         u  \n",
       "0      m      m  0.000010  0.000010  0.994950  0.000010  \n",
       "1      m      c  0.002193  0.085109  0.039649  0.000010  \n",
       "2      c      c  0.000010  0.977033  0.300756  0.001255  \n",
       "3      m      a  0.999206  0.000010  0.132974  0.000010  \n",
       "4      m      m  0.000010  0.939923  0.974053  0.000010  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2simple = {\n",
    "    'ABUSE': 'a',\n",
    "    'CONSUMPTION': 'c',\n",
    "    'MENTION': 'm',\n",
    "    'UNRELATED': 'u'\n",
    "}\n",
    "\n",
    "abbrev2fullname =  mapping={\n",
    "    'a': 'ABUSE',\n",
    "    'c': 'CONSUMPTION',\n",
    "    'm': 'MENTION',\n",
    "    'u': 'UNRELATED'\n",
    "}\n",
    "\n",
    "def swap_lab(val, mapping={\n",
    "    'a': 'ABUSE',\n",
    "    'c': 'CONSUMPTION',\n",
    "    'm': 'MENTION',\n",
    "    'u': 'UNRELATED'\n",
    "}):\n",
    "    \n",
    "    return mapping.get(val)\n",
    "\n",
    "def catify(doc, mapping):\n",
    "    top_cat, _ = get_top_cat(doc)\n",
    "    return mapping.get(top_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def write_out_predictions_4_evalofficial(\n",
    "    inputpath='preds/prediction-matrix-fasttext.csv',\n",
    "    text_col='text',\n",
    "    label_col = False,\n",
    "    mapping = {\n",
    "    'ABUSE': 'a',\n",
    "    'CONSUMPTION': 'c',\n",
    "    'MENTION': 'm',\n",
    "    'UNRELATED': 'u'\n",
    "},\n",
    "    modelpath='saved-models/spacy-cnn',\n",
    "    preds_eval_official_base = 'preds/spacy-cnn-eval-official',\n",
    "    preds_matrix_path_base='preds/spacy-cnn-prediction-matrix',\n",
    "    preds_matrx= True, n_samples=20):\n",
    "    labels = list(mapping.keys())\n",
    "    print(f'loading spacy model from {modelpath} to predict labels: {\", \".join(labels)}')\n",
    "    nlp = spacy.load(modelpath)\n",
    "    df_in = pd.read_csv(inputpath)\n",
    "    if not n_samples:\n",
    "        n_samples = len(df_in)\n",
    "    df_in = df_in.head(n_samples)\n",
    "    outpath = f\"{preds_eval_official_base}-{n_samples}.csv\"\n",
    "    outpathm = f\"{preds_matrix_path_base}-{n_samples}.csv\"\n",
    "    if not label_col:\n",
    "        print(f\"input data:\\n{df_in[['tweetid', text_col]].head(3)}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"input data with predictions:\\n{df_in[['tweetid', text_col, label_col]].head(3)}\")\n",
    "\n",
    "    \n",
    "    tweetids = df_in['tweetid'].tolist()\n",
    "    tweet_texts = df_in[text_col].tolist()\n",
    "    \n",
    "    docs = list(nlp.pipe(tweet_texts))\n",
    "    print(f\"predicting on {n_samples} samples...\")\n",
    "    print(f\"gathering y_pred - the class with the the maximum score predicted by the model (how we get predicted class)\")\n",
    "    cats = [catify(doc, mapping=mapping) for doc in docs]\n",
    "    tweet_preds = list(zip(tweetids, cats))\n",
    "    \n",
    "    df_out = pd.DataFrame(data=tweet_preds,\n",
    "                          columns=['tweetid', 'Class'])\n",
    "    \n",
    "    print(f\"\\noutput data:\\n{df_out.head(3)}\")\n",
    "    \n",
    "    df_out.to_csv(outpath, index=False)\n",
    "    print(f'\\nwriting {n_samples} predictions to {outpath}')\n",
    "    \n",
    "    o = [{'tweetid': tweetid, 'y_pred': cat, 'text': text} for \n",
    "             tweetid, cat, text in list(zip(tweetids, cats, tweet_texts))]\n",
    "    o2 = None\n",
    "    if preds_matrx:\n",
    "        if label_col:\n",
    "            df_in[label_col] = df_in[label_col].map(str.strip)\n",
    "            label_cols = df_in[label_col].tolist()\n",
    "            pred_cats_dict_list2 = [{'tweetid': tweetidp[0], 'y_pred': tweetidp[1],\n",
    "            'text': doc.text, 'y_true': gt} for tweetidp, doc, gt in list(zip(tweet_preds, docs, label_cols))]\n",
    "            [pred_dic.update(doc.to_json()['cats']) for pred_dic, doc in list(\n",
    "            zip(pred_cats_dict_list2, docs))]\n",
    "    \n",
    "            print(f'printing a group of predictions for labels + scores for {\", \".join(labels)}')\n",
    "    \n",
    "            for i, dc in enumerate(pred_cats_dict_list2[:3]):\n",
    "                pprint.pprint(dc)\n",
    "            o2 = pred_cats_dict_list2\n",
    "        \n",
    "        else:\n",
    "            pred_cats_dict_list = [{'tweetid': tweetidp[0],\n",
    "                                    'y_pred': tweetidp[1],\n",
    "            'text': doc.text,\n",
    "            } for tweetidp, doc in list(zip(tweet_preds, docs))]\n",
    "            [pred_dic.update(doc.to_json()['cats']) for pred_dic, doc in list(\n",
    "                zip(pred_cats_dict_list, docs))]\n",
    "            print(f'sample preds')\n",
    "            for i, dc in enumerate(pred_cats_dict_list[:3]):\n",
    "                pprint.pprint(dc)\n",
    "            o2 = pred_cats_dict_list\n",
    "            \n",
    " \n",
    "        df_preds_matrix = pd.DataFrame(o2)\n",
    "        df_preds_matrix[['tweetid',\n",
    " 'text',\n",
    " 'y_true',\n",
    " 'y_pred',\n",
    " 'ABUSE',\n",
    " 'CONSUMPTION',\n",
    " 'MENTION',\n",
    " 'UNRELATED']].to_csv(outpathm, index=False)\n",
    "    return o, o2\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "##df1, df2 = write_out_predictions_4_evalofficial(label_col='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading spacy model from saved-models/spacy-cnn to predict labels: ABUSE, CONSUMPTION, MENTION, UNRELATED\n",
      "input data with predictions:\n",
      "               tweetid                                               text  \\\n",
      "0  1201409307167862784        can somebody tell me what morphine is for ?   \n",
      "1  1200007750383738885  <number> mg . <number> of my x <number> i feee...   \n",
      "2  1199244035006902272  oh hello crippling anxiety , let ’ s drive hom...   \n",
      "\n",
      "  y_true  \n",
      "0      m  \n",
      "1      m  \n",
      "2      c  \n",
      "predicting on 2635 samples...\n",
      "gathering y_pred - the class with the the maximum score predicted by the model (how we get predicted class)\n",
      "\n",
      "output data:\n",
      "               tweetid Class\n",
      "0  1201409307167862784     m\n",
      "1  1200007750383738885     m\n",
      "2  1199244035006902272     c\n",
      "\n",
      "writing 2635 predictions to preds/spacy-cnn-eval-official-2635.csv\n",
      "printing a group of predictions for labels + scores for ABUSE, CONSUMPTION, MENTION, UNRELATED\n",
      "{'ABUSE': 0.12959064543247223,\n",
      " 'CONSUMPTION': 0.058977238833904266,\n",
      " 'MENTION': 0.8111096620559692,\n",
      " 'UNRELATED': 0.0003224723332095891,\n",
      " 'text': 'can somebody tell me what morphine is for ?',\n",
      " 'tweetid': 1201409307167862784,\n",
      " 'y_pred': 'm',\n",
      " 'y_true': 'm'}\n",
      "{'ABUSE': 0.11257541179656982,\n",
      " 'CONSUMPTION': 0.11184533685445786,\n",
      " 'MENTION': 0.7741215825080872,\n",
      " 'UNRELATED': 0.0014576882822439075,\n",
      " 'text': '<number> mg . <number> of my x <number> i feeeeeeeeeeel goooooooood '\n",
      "         'like im on suboxone or methadone',\n",
      " 'tweetid': 1200007750383738885,\n",
      " 'y_pred': 'm',\n",
      " 'y_true': 'm'}\n",
      "{'ABUSE': 0.007262896280735731,\n",
      " 'CONSUMPTION': 0.6339627504348755,\n",
      " 'MENTION': 0.34976696968078613,\n",
      " 'UNRELATED': 0.009007385931909084,\n",
      " 'text': 'oh hello crippling anxiety , let ’ s drive home from pittsburgh '\n",
      "         'shall we ? ! ativan',\n",
      " 'tweetid': 1199244035006902272,\n",
      " 'y_pred': 'c',\n",
      " 'y_true': 'c'}\n"
     ]
    }
   ],
   "source": [
    "all_off, all_matrix = write_out_predictions_4_evalofficial(n_samples=False, label_col='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tweetid', 'y_pred', 'text', 'y_true', 'ABUSE', 'CONSUMPTION',\n",
      "       'MENTION', 'UNRELATED'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>text</th>\n",
       "      <th>y_true</th>\n",
       "      <th>ABUSE</th>\n",
       "      <th>CONSUMPTION</th>\n",
       "      <th>MENTION</th>\n",
       "      <th>UNRELATED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201409307167862784</td>\n",
       "      <td>m</td>\n",
       "      <td>can somebody tell me what morphine is for ?</td>\n",
       "      <td>m</td>\n",
       "      <td>0.129591</td>\n",
       "      <td>0.058977</td>\n",
       "      <td>0.811110</td>\n",
       "      <td>0.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200007750383738885</td>\n",
       "      <td>m</td>\n",
       "      <td>&lt;number&gt; mg . &lt;number&gt; of my x &lt;number&gt; i feee...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.112575</td>\n",
       "      <td>0.111845</td>\n",
       "      <td>0.774122</td>\n",
       "      <td>0.001458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1199244035006902272</td>\n",
       "      <td>c</td>\n",
       "      <td>oh hello crippling anxiety , let ’ s drive hom...</td>\n",
       "      <td>c</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.633963</td>\n",
       "      <td>0.349767</td>\n",
       "      <td>0.009007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1199782125609902084</td>\n",
       "      <td>m</td>\n",
       "      <td>pop a adderall we gone fuck all night</td>\n",
       "      <td>m</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.169169</td>\n",
       "      <td>0.736982</td>\n",
       "      <td>0.002283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1199783941764517889</td>\n",
       "      <td>c</td>\n",
       "      <td>fake exercise facts a xanax a day keeps the tr...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.333943</td>\n",
       "      <td>0.338942</td>\n",
       "      <td>0.318412</td>\n",
       "      <td>0.008703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2630</th>\n",
       "      <td>1200980670782300160</td>\n",
       "      <td>m</td>\n",
       "      <td>_u that was not annie hall or diane keaton tha...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.312474</td>\n",
       "      <td>0.139349</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>0.038582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>1199509721868374022</td>\n",
       "      <td>c</td>\n",
       "      <td>_u suboxone for opiate dependent individuals d...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.020803</td>\n",
       "      <td>0.749869</td>\n",
       "      <td>0.224500</td>\n",
       "      <td>0.004828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2632</th>\n",
       "      <td>1198691681119490050</td>\n",
       "      <td>m</td>\n",
       "      <td>small brain : love lil pump med brain : xanax ...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.272467</td>\n",
       "      <td>0.338632</td>\n",
       "      <td>0.366688</td>\n",
       "      <td>0.022213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2633</th>\n",
       "      <td>1200884551108714497</td>\n",
       "      <td>c</td>\n",
       "      <td>_u do they have a physician ? many will give f...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.105011</td>\n",
       "      <td>0.457535</td>\n",
       "      <td>0.428604</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2634</th>\n",
       "      <td>1198545033261199361</td>\n",
       "      <td>m</td>\n",
       "      <td>_u _u _u the uninformed would think that the s...</td>\n",
       "      <td>m</td>\n",
       "      <td>0.148014</td>\n",
       "      <td>0.176216</td>\n",
       "      <td>0.675250</td>\n",
       "      <td>0.000521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2635 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweetid y_pred  \\\n",
       "0     1201409307167862784      m   \n",
       "1     1200007750383738885      m   \n",
       "2     1199244035006902272      c   \n",
       "3     1199782125609902084      m   \n",
       "4     1199783941764517889      c   \n",
       "...                   ...    ...   \n",
       "2630  1200980670782300160      m   \n",
       "2631  1199509721868374022      c   \n",
       "2632  1198691681119490050      m   \n",
       "2633  1200884551108714497      c   \n",
       "2634  1198545033261199361      m   \n",
       "\n",
       "                                                   text y_true     ABUSE  \\\n",
       "0           can somebody tell me what morphine is for ?      m  0.129591   \n",
       "1     <number> mg . <number> of my x <number> i feee...      m  0.112575   \n",
       "2     oh hello crippling anxiety , let ’ s drive hom...      c  0.007263   \n",
       "3                 pop a adderall we gone fuck all night      m  0.091566   \n",
       "4     fake exercise facts a xanax a day keeps the tr...      m  0.333943   \n",
       "...                                                 ...    ...       ...   \n",
       "2630  _u that was not annie hall or diane keaton tha...      m  0.312474   \n",
       "2631  _u suboxone for opiate dependent individuals d...      m  0.020803   \n",
       "2632  small brain : love lil pump med brain : xanax ...      m  0.272467   \n",
       "2633  _u do they have a physician ? many will give f...      m  0.105011   \n",
       "2634  _u _u _u the uninformed would think that the s...      m  0.148014   \n",
       "\n",
       "      CONSUMPTION   MENTION  UNRELATED  \n",
       "0        0.058977  0.811110   0.000322  \n",
       "1        0.111845  0.774122   0.001458  \n",
       "2        0.633963  0.349767   0.009007  \n",
       "3        0.169169  0.736982   0.002283  \n",
       "4        0.338942  0.318412   0.008703  \n",
       "...           ...       ...        ...  \n",
       "2630     0.139349  0.509596   0.038582  \n",
       "2631     0.749869  0.224500   0.004828  \n",
       "2632     0.338632  0.366688   0.022213  \n",
       "2633     0.457535  0.428604   0.008850  \n",
       "2634     0.176216  0.675250   0.000521  \n",
       "\n",
       "[2635 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_preds_df = pd.DataFrame(all_matrix)\n",
    "print(matrix_preds_df.columns)\n",
    "matrix_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this case all2 is none --> foor writing out just eval4official\n",
    "# all1, all2 = write_out_predictions_4_evalofficial(n_samples=False, preds_matrx=False)\n",
    "# all2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.20      0.08      0.12       448\n",
      "           c       0.24      0.20      0.22       730\n",
      "           m       0.50      0.68      0.58      1353\n",
      "           u       0.07      0.01      0.02       104\n",
      "\n",
      "    accuracy                           0.42      2635\n",
      "   macro avg       0.25      0.24      0.23      2635\n",
      "weighted avg       0.36      0.42      0.38      2635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sklm\n",
    "\n",
    "y_true = matrix_preds_df['y_true']\n",
    "y_pred = matrix_preds_df['y_pred']\n",
    "print(f\"{sklm.classification_report(y_true=y_true, y_pred=y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tweetid',\n",
       " 'text',\n",
       " 'y_true',\n",
       " 'y_pred',\n",
       " 'ABUSE',\n",
       " 'CONSUMPTION',\n",
       " 'MENTION',\n",
       " 'UNRELATED']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_order_class_abbrv = ['tweetid', 'text', 'y_true', 'y_pred', 'a', 'c', 'm', 'u']\n",
    "[abbrev2fullname.get(col, col) for col in col_order_class_abbrv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data-orig/validation.csv', 'data-orig/train.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "dataorig_files = glob.glob('data-orig/*.csv')\n",
    "dataorig_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([pd.read_csv(f) for f in dataorig_files])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13172"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_rows,_ = full_df.shape\n",
    "num_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>c</th>\n",
       "      <th>m</th>\n",
       "      <th>u</th>\n",
       "      <th>metadata</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1201409307167862784</td>\n",
       "      <td>Can somebody tell me what morphine is for?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1200007750383738885</td>\n",
       "      <td>1.2 mg .02 of my x 6 i feeeeeeeeeeel goooooooo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1199244035006902272</td>\n",
       "      <td>Oh hello crippling anxiety, let’s drive home f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1199782125609902084</td>\n",
       "      <td>Pop a adderall we gone fuck all night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1199783941764517889</td>\n",
       "      <td>#fakeexercisefacts a xanax a day keeps the tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10532</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1201785605576937472</td>\n",
       "      <td>No OK for real I actually deeply, deeply regre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10533</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1201906257344512001</td>\n",
       "      <td>_U _U _U _U ugh a consulting attending refused...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10534</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1200352805925670917</td>\n",
       "      <td>i took adderall and no longer want to kms so w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10535</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1201881741499215877</td>\n",
       "      <td>Adderall but for Emotions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10536</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1200753303631605760</td>\n",
       "      <td>_U amphetamine, think its like adderall</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13172 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       a  c  m  u             metadata  \\\n",
       "0      0  0  1  0  1201409307167862784   \n",
       "1      0  0  1  0  1200007750383738885   \n",
       "2      0  1  0  0  1199244035006902272   \n",
       "3      0  0  1  0  1199782125609902084   \n",
       "4      0  0  1  0  1199783941764517889   \n",
       "...   .. .. .. ..                  ...   \n",
       "10532  1  0  0  0  1201785605576937472   \n",
       "10533  0  0  1  0  1201906257344512001   \n",
       "10534  0  1  0  0  1200352805925670917   \n",
       "10535  0  0  1  0  1201881741499215877   \n",
       "10536  0  0  1  0  1200753303631605760   \n",
       "\n",
       "                                                    text  \n",
       "0             Can somebody tell me what morphine is for?  \n",
       "1      1.2 mg .02 of my x 6 i feeeeeeeeeeel goooooooo...  \n",
       "2      Oh hello crippling anxiety, let’s drive home f...  \n",
       "3                  Pop a adderall we gone fuck all night  \n",
       "4      #fakeexercisefacts a xanax a day keeps the tra...  \n",
       "...                                                  ...  \n",
       "10532  No OK for real I actually deeply, deeply regre...  \n",
       "10533  _U _U _U _U ugh a consulting attending refused...  \n",
       "10534  i took adderall and no longer want to kms so w...  \n",
       "10535                          Adderall but for Emotions  \n",
       "10536            _U amphetamine, think its like adderall  \n",
       "\n",
       "[13172 rows x 6 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_col = 'class'\n",
    "text_col = 'unprocessed_text'\n",
    "meta_cols = ['tweetid',]\n",
    "full_df['y_true'] = full_df[label_col].map(str.strip)\n",
    "one_hot = ['y_true',]\n",
    "\n",
    "for col in one_hot:\n",
    "    new_data = full_df.loc[:,col]\n",
    "    \n",
    "new_data = pd.get_dummies(new_data)\n",
    "\n",
    "new_data['metadata'] = full_df.loc[:, 'tweetid']\n",
    "new_data['text'] = full_df.loc[:, text_col]\n",
    "new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = full_df.sample(10)[text_col].tolist()\n",
    "web = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "nlp = spacy.load(\"spacy-cnn-twitter-glove\")\n",
    "#nlp.add_pipe()\n",
    "\n",
    "#docs = list(nlp.pipe(texts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcat = nlp.get_pipe(\"textcat\")\n",
    "web.add_pipe(textcat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('tagger', <spacy.pipeline.pipes.Tagger object at 0x12a80d210>), ('parser', <spacy.pipeline.pipes.DependencyParser object at 0x190031980>), ('ner', <spacy.pipeline.pipes.EntityRecognizer object at 0x190031830>), ('textcat', <spacy.pipeline.pipes.TextCategorizer object at 0x150e01990>)]\n"
     ]
    }
   ],
   "source": [
    "print(web.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oxycontin is a great drug if you wanna be sad and constipated\n",
      "\n",
      "\n",
      "oxycontin oxycontin PROPN NNP nsubj xxxx True False\n",
      "is be AUX VBZ ROOT xx True True\n",
      "a a DET DT det x True True\n",
      "great great ADJ JJ amod xxxx True False\n",
      "drug drug NOUN NN attr xxxx True False\n",
      "if if SCONJ IN mark xx True True\n",
      "you -PRON- PRON PRP nsubj xxx True True\n",
      "wanna wanna VERB VBP advcl xxxx True False\n",
      "be be AUX VB xcomp xx True True\n",
      "sad sad ADJ JJ acomp xxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "constipated constipated ADJ JJ conj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "docs= list(web.pipe(texts))\n",
    "for i, doc in enumerate(docs):\n",
    "    print(\" \".join(token.text for token in doc))\n",
    "    print(\"\\n\")\n",
    "    for token in doc:\n",
    "\n",
    "        print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop)\n",
    "    break\n",
    "   # print(doc.to_json())\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['label'] = full_df.loc[:,'class']\n",
    "new_data['label'] = new_data['label'].map(str.strip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 - 15\n",
    "85 - 65\n",
    "new_data[['label', 'unprocessed_text', 'tweetid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'(array([    1,     4,     5, ..., 13168, 13170, 13171]), slice(None, None, None))' is an invalid key",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4f6f674e50dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#Select Validation rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mval_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdiff1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrn_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mnew_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrn_rows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/patenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2994\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2995\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2996\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/patenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 )\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(array([    1,     4,     5, ..., 13168, 13170, 13171]), slice(None, None, None))' is an invalid key"
     ]
    }
   ],
   "source": [
    "np.random.seed(13)\n",
    "trn_rows = np.sort(np.random.choice(num_rows, size = int(num_rows * .85), replace = False))\n",
    "\n",
    "#Select Validation rows\n",
    "val_rows = np.setdiff1d(np.arange(num_rows), trn_rows)\n",
    "\n",
    "#Split dataset\n",
    "\n",
    "\n",
    "#Select Training rows\n",
    "np.random.seed(0)\n",
    "trn_rows = np.sort(np.random.choice(num_rows, size = int(num_rows * .7), replace = False))\n",
    "\n",
    "#Select Validation rows\n",
    "val_rows = np.setdiff1d(np.arange(num_rows), trn_rows)\n",
    "new_data[trn_rows,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split dataset\n",
    "trn_data, val_data = data[trn_rows,1:], data[val_rows,1:]\n",
    "trn_Y, val_Y = data[trn_rows,0], data[val_rows,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
