{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text preprocessing foor fastText\n",
    "* fastText for multiclass input data looks like a flat file delimited with ```__label__ + label_class + <\\space> + preprocessed_text```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fasttext in /opt/conda/lib/python3.7/site-packages (0.9.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from fasttext) (1.18.1)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/conda/lib/python3.7/site-packages (from fasttext) (2.4.3)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from fasttext) (45.2.0.post20200209)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (1.0.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: gcsfs in /opt/conda/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.7/site-packages (from gcsfs) (0.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gcsfs) (2.23.0)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.7/site-packages (from gcsfs) (1.11.2)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from gcsfs) (0.6.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from gcsfs) (4.4.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib->gcsfs) (1.2.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (1.25.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (2019.11.28)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (45.2.0.post20200209)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (1.14.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.0.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.7/site-packages (from rsa<4.1,>=3.1.4->google-auth>=1.2->gcsfs) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install fasttext\n",
    "! pip install pandas\n",
    "! pip install gcsfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing packgs and creating filespace\n",
    "import gcsfs\n",
    "import fasttext\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='sm4h-rxspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting at 2020-03-25 09:20\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "dt = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "print(f\"starting at {dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n",
      "<class 'str'> CANT WAIT for the new season of #TwinPeaks ＼(^o^)／!!! #davidlynch #tvseries :)))\n",
      "cant wait for the new season of twin peaks ＼(^o^)／ ! ! ! david lynch tv series <happy>\n",
      "<class 'str'> I saw the new #johndoe movie and it suuuuucks!!! WAISTED $10... #badmovies :/\n",
      "i saw the new john doe movie and it suuuuucks ! ! ! waisted <money> . . . bad movies <annoyed>\n",
      "<class 'str'> @SentimentSymp:  can't wait for the Nov 9 #Sentiment talks!  YAAAAAAY !!! :-D http://sentimentsymposium.com/.\n",
      "<user> : can not wait for the <date> sentiment talks ! yaaaaaay ! ! ! <laugh> <url>\n"
     ]
    }
   ],
   "source": [
    "# creating text_preprocessing with ekphrasis\n",
    "import re\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that will be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={},\n",
    "#     annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "#         'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n",
    "\n",
    "sentences = [\n",
    "    \"CANT WAIT for the new season of #TwinPeaks ＼(^o^)／!!! #davidlynch #tvseries :)))\",\n",
    "    \"I saw the new #johndoe movie and it suuuuucks!!! WAISTED $10... #badmovies :/\",\n",
    "    \"@SentimentSymp:  can't wait for the Nov 9 #Sentiment talks!  YAAAAAAY !!! :-D http://sentimentsymposium.com/.\"\n",
    "]\n",
    "\n",
    "for s in sentences:\n",
    "    print(type(s), s)\n",
    "    print(\" \".join(text_processor.pre_process_doc(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fasttext_label(val):\n",
    "    val = str(val)\n",
    "    val = val.strip()\n",
    "    return '__label__' + val\n",
    "\n",
    "def preprocess_fasttext(s, lower=True):\n",
    "    tokens = text_processor.pre_process_doc(s)\n",
    "    if lower:\n",
    "        return ' '.join([t.lower() for t in tokens])\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def main(inpath, outpath, text_col='unprocessed_text', label_col='class'):\n",
    "    \n",
    "    df = pd.read_csv(inpath)\n",
    "    n = len(df)\n",
    "    print(f\"read in {n} samples from {inpath}\")\n",
    "    \n",
    "    df['label'] = df[label_col].map(create_fasttext_label)\n",
    "    df['text'] = df[text_col].replace('\\n', ' ', regex=True).replace('\\t', ' ', regex=True)\n",
    "    df['text'] = df['text'].map(str)\n",
    "    df['text'] = df['text'].map(preprocess_fasttext)\n",
    "    fasttext_df = df[['label', 'text']]\n",
    "    fasttext_df.to_csv(f\"{outpath}\", index=False, sep=' ',\n",
    "                       header=False, quoting=csv.QUOTE_NONE,\n",
    "                      quotechar=\"\", escapechar=\" \")\n",
    "    print(f\"wrote out fasttext prepared text to {outpath}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_pth = \"gs://sm4h-rxspace/task4/train.csv\"\n",
    "dev_pth = \"gs://sm4h-rxspace/task4/validation.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 10537 samples from gs://sm4h-rxspace/task4/train.csv\n",
      "wrote out fasttext prepared text to fastText-0.9.1/data/tweets-fasttext.train\n"
     ]
    }
   ],
   "source": [
    "main(inpath=train_pth, outpath=\"fastText-0.9.1/data/tweets-fasttext.train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 2635 samples from gs://sm4h-rxspace/task4/validation.csv\n",
      "wrote out fasttext prepared text to fastText-0.9.1/data/tweets-fasttext.dev\n"
     ]
    }
   ],
   "source": [
    "main(inpath=dev_pth, outpath=\"fastText-0.9.1/data/tweets-fasttext.dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = fasttext.train_supervised(input='fastText-0.9.1/data/tweets-fasttext.train',\n",
    "                                  lr=0.5, epoch=25,\n",
    "                                  wordNgrams=2,\n",
    "                                  bucket=200000,\n",
    "                                  dim=100,\n",
    "                                  loss='ova')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('fasttext_model_tweets.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "verbose_map = {\n",
    "    'a': 'ABUSE',\n",
    "    'm': 'MENTION',\n",
    "    'u': 'UNRELATED',\n",
    "    'c': 'CONSUMPTION'\n",
    "              }\n",
    "\n",
    "def predict_twitter(inpath, outpath, text_col='unprocessed_text', label_col='class', n_samples=10):\n",
    "    \n",
    "    df = pd.read_csv(inpath)\n",
    "    if n_samples is None:\n",
    "        n_samples = len(df)\n",
    "        \n",
    "    df = df.sample(n_samples)\n",
    "\n",
    "    print(f\"read in {n_samples} samples from {inpath}\")\n",
    "    \n",
    "    df['label'] = df[label_col].map(create_fasttext_label)\n",
    "    df['text'] = df[text_col].replace('\\n', ' ', regex=True).replace('\\t', ' ', regex=True)\n",
    "    df['text'] = df['text'].map(str)\n",
    "    df['text'] = df['text'].map(preprocess_fasttext)\n",
    "    preds_list = []\n",
    "    for i, row in df.iterrows():\n",
    "        tweetid = row['tweetid']\n",
    "        text = row['text']\n",
    "        print(text)\n",
    "        pred_lb, score = model.predict(text)\n",
    "        pred = pred_lb[0].replace('__label__', '')\n",
    "        print(f'pred class: {verbose_map.get(pred)}\\npred score {round(score[0], 4)}')\n",
    "        true_label = row[label_col]\n",
    "        print(f'true class: {verbose_map.get(true_label)}')\n",
    "        preds_list.append({'tweetid': tweetid,\n",
    "                          'Class': pred})\n",
    "        \n",
    "    fasttext_df = pd.DataFrame(preds_list)\n",
    "    fasttext_df.to_csv(f\"{outpath}\", index=False, quoting=csv.QUOTE_NONE,\n",
    "                      quotechar=\"\", escapechar=\" \")\n",
    "    print(f\"wrote out fasttext prepared text to {outpath}\")\n",
    "        \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read in 20 samples from gs://sm4h-rxspace/task4/train.csv\n",
      "<time> and i am already on tramadol 😞 🔫\n",
      "pred class: CONSUMPTION\n",
      "pred score 0.9996\n",
      "true class: CONSUMPTION\n",
      "day <number> of being sober from addy and xanax and feelin good 😇 gonna keep this up idc how difficult it gets\n",
      "pred class: ABUSE\n",
      "pred score 0.9962\n",
      "true class: ABUSE\n",
      "if it ’ s not too late can someone give xan to a couple of xanax so it can calm down a bit before tomorrow ?\n",
      "pred class: MENTION\n",
      "pred score 0.9922\n",
      "true class: MENTION\n",
      "_u oh c ' mon , that ' s knudepunkt but on valium and with business cards . . .\n",
      "pred class: MENTION\n",
      "pred score 1.0\n",
      "true class: MENTION\n",
      "life of a college kid : \" i am about to take an adderall and drink a beer with it . \" - _u\n",
      "pred class: MENTION\n",
      "pred score 0.9935\n",
      "true class: MENTION\n",
      "i changed for each one of my adderall high where i feel like mario after he ' s found a star .\n",
      "pred class: ABUSE\n",
      "pred score 1.0\n",
      "true class: ABUSE\n",
      "so done with this adderall 😒\n",
      "pred class: CONSUMPTION\n",
      "pred score 1.0\n",
      "true class: CONSUMPTION\n",
      "_u _u no we should make big pharma fund substance abuse treatment centers for heavily marketing oxycontin to drs and hospitals and covering up the addictive properties of the painkillers they pedal that have exacerbated the drug problem we have . next .\n",
      "pred class: MENTION\n",
      "pred score 1.0\n",
      "true class: MENTION\n",
      "_u _u it ' s worse than that . ibogaine can cure heroin addiction much more efficiently than methadone . it ' s legal in europe & asia . but , the patent on it expired . the drug company could not make money off it , so they never applied for fda approval .\n",
      "pred class: MENTION\n",
      "pred score 1.0\n",
      "true class: MENTION\n",
      "on the block i am magical see me at ya college campus baggy full of adderall\n",
      "pred class: MENTION\n",
      "pred score 0.9909\n",
      "true class: MENTION\n",
      "_u maybe like an adderall like substance that helps them concentrate but is banned ? 🤷\n",
      "pred class: MENTION\n",
      "pred score 1.0\n",
      "true class: MENTION\n",
      "a british citizen has been jailed for <number> years in egypt for taking tramadol in to there country as its illegal there ( shock as shit ) but it ’ s there rules and this is why you need to no about where your traveling to especially with medication .\n",
      "pred class: MENTION\n",
      "pred score 0.9958\n",
      "true class: MENTION\n",
      "so . i might be opening a big ol ' can of worms here , but i ' d like info about tramadol , esp as relates to eds and mcas patients . thinking about switching over from as - needed to a scheduled regimen .\n",
      "pred class: MENTION\n",
      "pred score 0.9927\n",
      "true class: MENTION\n",
      "man that hydrocodone be having me out for hellas\n",
      "pred class: CONSUMPTION\n",
      "pred score 1.0\n",
      "true class: CONSUMPTION\n",
      "_u rt _u : adderall had me cleaning my mirrors when all i wanted to do was take a selfie\n",
      "pred class: MENTION\n",
      "pred score 0.9993\n",
      "true class: MENTION\n",
      "_u on codeine , still got naproxen and some diazepam left . she said i shouldnt have been prescribed as much as i did . i ain ' t ( <money>\n",
      "pred class: CONSUMPTION\n",
      "pred score 0.9959\n",
      "true class: CONSUMPTION\n",
      "the valium is probably helping too .\n",
      "pred class: CONSUMPTION\n",
      "pred score 1.0\n",
      "true class: CONSUMPTION\n",
      "saw a doctor to get my anxiety treated , was applauded for my article . surreal . also i have xanax now thank goodness\n",
      "pred class: CONSUMPTION\n",
      "pred score 1.0\n",
      "true class: CONSUMPTION\n",
      "best line of the trip yet . me : i can ’ t find my ativan ! ! ! mrs : how about some red licorice ? me : how about some prayers to st . anthony ! ! ! ativan found , all will soon be well in brian - land !\n",
      "pred class: CONSUMPTION\n",
      "pred score 0.9943\n",
      "true class: CONSUMPTION\n",
      "does anybody have any good recipes for adderall\n",
      "pred class: ABUSE\n",
      "pred score 0.9997\n",
      "true class: ABUSE\n",
      "wrote out fasttext prepared text to preds-validation-fasttext-twitter-model-samples.csv\n"
     ]
    }
   ],
   "source": [
    "predict_twitter(inpath=train_pth, outpath='preds-validation-fasttext-twitter-model-samples.csv', n_samples=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
