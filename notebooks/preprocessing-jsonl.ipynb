{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gcsfs in /opt/conda/lib/python3.7/site-packages (0.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from gcsfs) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /opt/conda/lib/python3.7/site-packages (from gcsfs) (0.4.1)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from gcsfs) (0.6.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from gcsfs) (4.4.2)\n",
      "Requirement already satisfied: google-auth>=1.2 in /opt/conda/lib/python3.7/site-packages (from gcsfs) (1.11.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (1.25.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->gcsfs) (2.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib->gcsfs) (1.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (1.14.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (3.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (0.2.7)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth>=1.2->gcsfs) (46.0.0.post20200311)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.0.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs) (0.4.8)\n",
      "Requirement already satisfied: jsonlines in /opt/conda/lib/python3.7/site-packages (1.2.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from jsonlines) (1.14.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: ekphrasis in /opt/conda/lib/python3.7/site-packages (0.5.1)\n",
      "Requirement already satisfied: ftfy in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (5.7)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (3.4.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (4.33.0)\n",
      "Requirement already satisfied: ujson in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (2.0.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (3.2.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (0.4.3)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from ekphrasis) (1.18.1)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from ftfy->ekphrasis) (0.1.8)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk->ekphrasis) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->ekphrasis) (2.4.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->ekphrasis) (46.0.0.post20200311)\n"
     ]
    }
   ],
   "source": [
    "! pip install gcsfs\n",
    "! pip install jsonlines\n",
    "! pip install pandas\n",
    "! pip install ekphrasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:\n",
      "2020-03-25 08:06\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gcsfs\n",
    "\n",
    "# setting up file system to be ble to read from buckets\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='sm4h-rxspace')\n",
    "\n",
    "now = datetime.now()\n",
    "dt = now.strftime('%Y-%m-%d %H:%M')\n",
    "print(f'start time:\\n{dt}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution(df, col='class'):\n",
    "    \"\"\"gives distribution of a column from a pandas data-frame \"\"\"\n",
    "    df_out = df[col].value_counts()\n",
    "    n_train = df.shape[0]\n",
    "    print(f\"loaded {n_train} samples\\n\")\n",
    "\n",
    "    df_out = pd.DataFrame(df_out)\n",
    "    df_out.columns = ['class counts']\n",
    "    df_out['class %'] = round(100 * df_out['class counts'] / n_train, 2)\n",
    "    return df_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train path : gs://sm4h-rxspace/task4/train.csv\n",
      "dev path : gs://sm4h-rxspace/task4/validation.csv\n"
     ]
    }
   ],
   "source": [
    "train_path = \"gs://sm4h-rxspace/task4/train.csv\"\n",
    "dev_path = \"gs://sm4h-rxspace/task4/validation.csv\"\n",
    "print(f'train path : {train_path}\\ndev path : {dev_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded train from gs://sm4h-rxspace/task4/train.csv\n",
      "loaded 10537 samples\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class counts</th>\n",
       "      <th>class %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>5488</td>\n",
       "      <td>52.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>2940</td>\n",
       "      <td>27.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1685</td>\n",
       "      <td>15.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>424</td>\n",
       "      <td>4.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class counts  class %\n",
       "m  5488          52.08  \n",
       "c  2940          27.90  \n",
       "a  1685          15.99  \n",
       "u  424           4.02   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw = pd.read_csv(train_path)\n",
    "df_train_raw['class'] = df_train_raw['class'].map(str.strip)\n",
    "\n",
    "print(f'loaded train from {train_path}')\n",
    "get_distribution(df_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded dev from gs://sm4h-rxspace/task4/validation.csv..\n",
      "loaded 2635 samples\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class counts</th>\n",
       "      <th>class %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m</th>\n",
       "      <td>1353</td>\n",
       "      <td>51.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>730</td>\n",
       "      <td>27.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>448</td>\n",
       "      <td>17.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>u</th>\n",
       "      <td>104</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class counts  class %\n",
       "m  1353          51.35  \n",
       "c  730           27.70  \n",
       "a  448           17.00  \n",
       "u  104           3.95   "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val_raw = pd.read_csv(dev_path)\n",
    "df_val_raw['class'] = df_val_raw['class'].map(str.strip)\n",
    "\n",
    "print(f'loaded dev from {dev_path}..')\n",
    "get_distribution(df_val_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>unprocessed_text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1202189293432823810</td>\n",
       "      <td>_U _U i even see a lot of readmits on those. risperdal consta, abilify maintena, haldol lai, all of them.</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200504615760023552</td>\n",
       "      <td>_U valium o clock</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1201776570492489728</td>\n",
       "      <td>Stop Xanax 😂😂😂😂</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1200528076159029248</td>\n",
       "      <td>_U tbh it’s the valium i’m on rn prob</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1201420901633400832</td>\n",
       "      <td>_U i got mine pulled out about 6 years ago and the doctor prescribed me oxycodone but i never had pain. i just got high lol</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid  \\\n",
       "0  1202189293432823810   \n",
       "1  1200504615760023552   \n",
       "2  1201776570492489728   \n",
       "3  1200528076159029248   \n",
       "4  1201420901633400832   \n",
       "\n",
       "                                                                                                              unprocessed_text  \\\n",
       "0  _U _U i even see a lot of readmits on those. risperdal consta, abilify maintena, haldol lai, all of them.                     \n",
       "1  _U valium o clock                                                                                                             \n",
       "2  Stop Xanax 😂😂😂😂                                                                                                               \n",
       "3  _U tbh it’s the valium i’m on rn prob                                                                                         \n",
       "4  _U i got mine pulled out about 6 years ago and the doctor prescribed me oxycodone but i never had pain. i just got high lol   \n",
       "\n",
       "  class  \n",
       "0  m     \n",
       "1  m     \n",
       "2  m     \n",
       "3  c     \n",
       "4  a     "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw.head()[['tweetid', 'unprocessed_text', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading twitter - 1grams ...\n",
      "Reading twitter - 2grams ...\n",
      "Reading twitter - 1grams ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['_U _U i even see a lot of readmits on those. risperdal consta, abilify maintena, haldol lai, all of them.',\n",
       " '_U valium o clock',\n",
       " 'Stop Xanax 😂😂😂😂',\n",
       " '_U tbh it’s the valium i’m on rn prob',\n",
       " '_U i got mine pulled out about 6 years ago and the doctor prescribed me oxycodone but i never had pain. i just got high lol',\n",
       " \"Today is my 1 year vegan anniversary, also over a year since I've used a microwave and 1 year being clean of Vyvanse after struggling being on it for 8 years🤘\",\n",
       " 'Hurricane #Irma upgraded back to a Category-5 storm; maximum sustained winds 160 mph.   Can someone get this chick a xanax or soemthin????',\n",
       " \"_U I'm on 100mg of Pristiq as well as I'm on Tramadol which boosts serotonin levels, I'm a fucking monster mate\",\n",
       " 'last timethis haopened i spent two months taking morphine and spending50% of mydays bedbound so uh. hoping its just a onw off and not thatagain tbh!',\n",
       " '_U _U \"innovation isn\\'t as likely\" is a massive understatement btw. The only popular consumer products that the USSR invented were the Rubik\\'s cube, Tetris and Fanta Orange drink. And methadone if you want to include that.',\n",
       " \"“_U: 99.3% of the world's hydrocodone is used in the united states. 😳 #ascp15 #dea” wow!\"]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading text preprocessing\n",
    "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
    "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
    "from ekphrasis.dicts.emoticons import emoticons\n",
    "\n",
    "text_processor = TextPreProcessor(\n",
    "    # terms that waill be normalized\n",
    "    normalize=['url', 'email', 'percent', 'money', 'phone', 'user',\n",
    "        'time', 'url', 'date', 'number'],\n",
    "    # terms that will be annotated\n",
    "    annotate={},\n",
    "#     annotate={\"hashtag\", \"allcaps\", \"elongated\", \"repeated\",\n",
    "#         'emphasis', 'censored'},\n",
    "    fix_html=True,  # fix HTML tokens\n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for word segmentation \n",
    "    segmenter=\"twitter\", \n",
    "    \n",
    "    # corpus from which the word statistics are going to be used \n",
    "    # for spell correction\n",
    "    corrector=\"twitter\", \n",
    "    \n",
    "    unpack_hashtags=True,  # perform word segmentation on hashtags\n",
    "    unpack_contractions=True,  # Unpack contractions (can't -> can not)\n",
    "    spell_correct_elong=False,  # spell correction for elongated words\n",
    "    \n",
    "    # select a tokenizer. You can use SocialTokenizer, or pass your own\n",
    "    # the tokenizer, should take as input a string and return a list of tokens\n",
    "    tokenizer=SocialTokenizer(lowercase=True).tokenize,\n",
    "    \n",
    "    # list of dictionaries, for replacing tokens extracted from the text,\n",
    "    # with other expressions. You can pass more than one dictionaries.\n",
    "    dicts=[emoticons]\n",
    ")\n",
    "\n",
    "sentences = df_train_raw['unprocessed_text'].tolist()[:11]\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'> _U _U i even see a lot of readmits on those. risperdal consta, abilify maintena, haldol lai, all of them.\n",
      "_u _u i even see a lot of readmits on those . risperdal consta , abilify maintena , haldol lai , all of them .\n",
      "<class 'str'> _U valium o clock\n",
      "_u valium o clock\n",
      "<class 'str'> Stop Xanax 😂😂😂😂\n",
      "stop xanax 😂 😂 😂 😂\n",
      "<class 'str'> _U tbh it’s the valium i’m on rn prob\n",
      "_u tbh it ’ s the valium i ’ m on rn prob\n",
      "<class 'str'> _U i got mine pulled out about 6 years ago and the doctor prescribed me oxycodone but i never had pain. i just got high lol\n",
      "_u i got mine pulled out about <number> years ago and the doctor prescribed me oxycodone but i never had pain . i just got high lol\n",
      "<class 'str'> Today is my 1 year vegan anniversary, also over a year since I've used a microwave and 1 year being clean of Vyvanse after struggling being on it for 8 years🤘\n",
      "today is my <number> year vegan anniversary , also over a year since i have used a microwave and <number> year being clean of vyvanse after struggling being on it for <number> years 🤘\n",
      "<class 'str'> Hurricane #Irma upgraded back to a Category-5 storm; maximum sustained winds 160 mph.   Can someone get this chick a xanax or soemthin????\n",
      "hurricane irma upgraded back to a category - <number> storm ; maximum sustained winds <number> mph . can someone get this chick a xanax or soemthin ? ? ? ?\n",
      "<class 'str'> _U I'm on 100mg of Pristiq as well as I'm on Tramadol which boosts serotonin levels, I'm a fucking monster mate\n",
      "_u i am on 1 0 0 mg of pristiq as well as i am on tramadol which boosts serotonin levels , i am a fucking monster mate\n",
      "<class 'str'> last timethis haopened i spent two months taking morphine and spending50% of mydays bedbound so uh. hoping its just a onw off and not thatagain tbh!\n",
      "last timethis haopened i spent two months taking morphine and spending50 % of mydays bedbound so uh . hoping its just a onw off and not thatagain tbh !\n",
      "<class 'str'> _U _U \"innovation isn't as likely\" is a massive understatement btw. The only popular consumer products that the USSR invented were the Rubik's cube, Tetris and Fanta Orange drink. And methadone if you want to include that.\n",
      "_u _u \" innovation is not as likely \" is a massive understatement btw . the only popular consumer products that the ussr invented were the rubik ' s cube , tetris and fanta orange drink . and methadone if you want to include that .\n",
      "<class 'str'> “_U: 99.3% of the world's hydrocodone is used in the united states. 😳 #ascp15 #dea” wow!\n",
      "“ _u : <percent> of the world ' s hydrocodone is used in the united states . 😳 ascp15 dea ” wow !\n"
     ]
    }
   ],
   "source": [
    "for s in sentences:\n",
    "    print(type(s), s)\n",
    "    print(\" \".join(text_processor.pre_process_doc(s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_tweet_text(s):\n",
    "    \"\"\"using ekphrasis preprocessng \"\"\"\n",
    "    return \" \".join(text_processor.pre_process_doc(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def write_df(df, out_path, text_col='text', label_col='class', metadata=None):\n",
    "    \"\"\"\n",
    "    takes a datafrmae, writes out text col, label col\n",
    "    \"\"\"\n",
    "    \n",
    "    cnt = 0\n",
    "    with jsonlines.open(out_path, 'w') as writer:\n",
    "        for i, row in df.iterrows():\n",
    "            if metadata is None:\n",
    "                metadata_res = ''\n",
    "            metadata_res = row[metadata]\n",
    "            #tweetid = row['tweetid']\n",
    "            text = row[text_col]\n",
    "            text = preprocess_tweet_text(text)\n",
    "            label = row[label_col]\n",
    "            # to strip white spaces and etc\n",
    "            label = label.strip()\n",
    "            writer.write({\n",
    "                'text': text,\n",
    "                'label': label,\n",
    "                'metadata': metadata,\n",
    "\n",
    "            })\n",
    "            \n",
    "            \n",
    "            cnt += 1\n",
    "    print(f\"wrote {cnt} lines to {out_path}\")\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 10537 lines to train.jsonl\n"
     ]
    }
   ],
   "source": [
    "write_df(df_train_raw, out_path='train.jsonl', text_col='unprocessed_text', label_col='class', metadata='tweetid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 2635 lines to validation.jsonl\n"
     ]
    }
   ],
   "source": [
    "write_df(df_val_raw, out_path='validation.jsonl', text_col='unprocessed_text', label_col='class', metadata='tweetid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
