{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time:\n",
      "2020-03-25 04:02\n",
      "Requirement already satisfied: pandas==0.25.0 in /opt/conda/lib/python3.7/site-packages (0.25.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.0) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.0) (1.18.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas==0.25.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.6.1->pandas==0.25.0) (1.14.0)\n",
      "Collecting tqdm==4.33.0\n",
      "  Using cached tqdm-4.33.0-py2.py3-none-any.whl (50 kB)\n",
      "\u001b[31mERROR: snorkel 0.9.3 has requirement torch<1.2.0,>=1.1.0, but you'll have torch 1.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: en-core-web-md 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.43.0\n",
      "    Uninstalling tqdm-4.43.0:\n",
      "      Successfully uninstalled tqdm-4.43.0\n",
      "Successfully installed tqdm-4.33.0\n",
      "Requirement already satisfied: snorkel in /opt/conda/lib/python3.7/site-packages (0.9.3)\n",
      "Requirement already satisfied: scikit-learn<0.22.0,>=0.20.2 in /opt/conda/lib/python3.7/site-packages (from snorkel) (0.21.3)\n",
      "Requirement already satisfied: pandas<0.26.0,>=0.25.0 in /opt/conda/lib/python3.7/site-packages (from snorkel) (0.25.0)\n",
      "Requirement already satisfied: tensorboardX<2.0,>=1.6 in /opt/conda/lib/python3.7/site-packages (from snorkel) (1.9)\n",
      "Requirement already satisfied: munkres==1.1.2 in /opt/conda/lib/python3.7/site-packages (from snorkel) (1.1.2)\n",
      "Collecting torch<1.2.0,>=1.1.0\n",
      "  Using cached torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n",
      "Requirement already satisfied: networkx<2.4,>=2.2 in /opt/conda/lib/python3.7/site-packages (from snorkel) (2.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.33.0 in /opt/conda/lib/python3.7/site-packages (from snorkel) (4.33.0)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from snorkel) (1.4.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from snorkel) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn<0.22.0,>=0.20.2->snorkel) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas<0.26.0,>=0.25.0->snorkel) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas<0.26.0,>=0.25.0->snorkel) (2019.3)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/conda/lib/python3.7/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (3.11.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tensorboardX<2.0,>=1.6->snorkel) (1.14.0)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx<2.4,>=2.2->snorkel) (4.4.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.8.0->tensorboardX<2.0,>=1.6->snorkel) (46.0.0.post20200311)\n",
      "\u001b[31mERROR: allennlp 0.9.0 has requirement torch>=1.2.0, but you'll have torch 1.1.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "Successfully installed torch-1.1.0\n",
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (2.1.9)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy) (7.0.8)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.18.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.23.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.6.0)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.2.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc<7.1.0,>=7.0.8->spacy) (4.33.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Collecting en_core_web_md==2.1.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 95.4 MB 97 kB/s eta 0:00:0101\n",
      "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
      "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-py3-none-any.whl size=97126236 sha256=c14d1218b6108f9f243d8a8501fe754a9e7a430dc4ef064fc657789f5f2af996\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nzvlb2np/wheels/1a/4e/53/ca2bd8efb94658d2425a0a2d998ffddc2db7ea1378421f8565\n",
      "Successfully built en-core-web-md\n",
      "Installing collected packages: en-core-web-md\n",
      "  Attempting uninstall: en-core-web-md\n",
      "    Found existing installation: en-core-web-md 2.2.5\n",
      "    Uninstalling en-core-web-md-2.2.5:\n",
      "      Successfully uninstalled en-core-web-md-2.2.5\n",
      "Successfully installed en-core-web-md-2.1.0\n",
      "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n",
      "Requirement already satisfied: spacy-lookup in /opt/conda/lib/python3.7/site-packages (0.1.0)\n",
      "Requirement already satisfied: spacy<3.0.0,>=2.0.16 in /opt/conda/lib/python3.7/site-packages (from spacy-lookup) (2.1.9)\n",
      "Requirement already satisfied: flashtext>=2.7 in /opt/conda/lib/python3.7/site-packages (from spacy-lookup) (2.7)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (7.0.8)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (2.0.3)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (0.2.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (0.6.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (1.18.1)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (0.9.6)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from spacy<3.0.0,>=2.0.16->spacy-lookup) (2.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /opt/conda/lib/python3.7/site-packages (from thinc<7.1.0,>=7.0.8->spacy<3.0.0,>=2.0.16->spacy-lookup) (4.33.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.16->spacy-lookup) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.16->spacy-lookup) (1.25.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.16->spacy-lookup) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.16->spacy-lookup) (2.9)\n",
      "Requirement already satisfied: lemminflect in /opt/conda/lib/python3.7/site-packages (0.2.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from lemminflect) (1.18.1)\n",
      "Requirement already satisfied: pandas-profiling in /opt/conda/lib/python3.7/site-packages (2.4.0)\n",
      "Requirement already satisfied: jinja2>=2.8 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (2.11.1)\n",
      "Requirement already satisfied: matplotlib>=1.4 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (3.2.0)\n",
      "Requirement already satisfied: astropy in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (4.0)\n",
      "Requirement already satisfied: phik>=0.9.8 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (0.9.10)\n",
      "Requirement already satisfied: missingno>=0.4.2 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (0.4.2)\n",
      "Requirement already satisfied: htmlmin>=0.1.12 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (0.1.12)\n",
      "Requirement already satisfied: pandas>=0.19 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (0.25.0)\n",
      "Requirement already satisfied: confuse>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pandas-profiling) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2>=2.8->pandas-profiling) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=1.4->pandas-profiling) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=1.4->pandas-profiling) (1.18.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=1.4->pandas-profiling) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=1.4->pandas-profiling) (2.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib>=1.4->pandas-profiling) (2.8.1)\n",
      "Requirement already satisfied: joblib>=0.14.1 in /opt/conda/lib/python3.7/site-packages (from phik>=0.9.8->pandas-profiling) (0.14.1)\n",
      "Requirement already satisfied: jupyter-client>=5.2.3 in /opt/conda/lib/python3.7/site-packages (from phik>=0.9.8->pandas-profiling) (6.0.0)\n",
      "Requirement already satisfied: pytest>=4.0.2 in /opt/conda/lib/python3.7/site-packages (from phik>=0.9.8->pandas-profiling) (5.3.5)\n",
      "Requirement already satisfied: nbconvert>=5.3.1 in /opt/conda/lib/python3.7/site-packages (from phik>=0.9.8->pandas-profiling) (5.6.1)\n",
      "Requirement already satisfied: numba>=0.38.1 in /opt/conda/lib/python3.7/site-packages (from phik>=0.9.8->pandas-profiling) (0.48.0)\n",
      "Requirement already satisfied: pytest-pylint>=0.13.0 in /opt/conda/lib/python3.7/site-packages (from phik>=0.9.8->pandas-profiling) (0.14.1)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from phik>=0.9.8->pandas-profiling) (1.4.1)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from missingno>=0.4.2->pandas-profiling) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.19->pandas-profiling) (2019.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from confuse>=1.0.0->pandas-profiling) (5.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4->pandas-profiling) (46.0.0.post20200311)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=1.4->pandas-profiling) (1.14.0)\n",
      "Requirement already satisfied: tornado>=4.1 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (6.0.4)\n",
      "Requirement already satisfied: traitlets in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (4.3.3)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (4.6.3)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.7/site-packages (from jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (19.0.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.8.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (20.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (19.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (8.2.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (0.1.8)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (5.0.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.6.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (3.1.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (2.6.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.7/site-packages (from nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.8.4)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /opt/conda/lib/python3.7/site-packages (from numba>=0.38.1->phik>=0.9.8->pandas-profiling) (0.31.0)\n",
      "Requirement already satisfied: pylint>=1.4.5 in /opt/conda/lib/python3.7/site-packages (from pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (2.4.4)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from traitlets->jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (4.4.2)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets->jupyter-client>=5.2.3->phik>=0.9.8->pandas-profiling) (0.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest>=4.0.2->phik>=0.9.8->pandas-profiling) (3.1.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.7/site-packages (from nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (3.2.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.7/site-packages (from bleach->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.5.1)\n",
      "Requirement already satisfied: astroid<2.4,>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (2.3.3)\n",
      "Requirement already satisfied: isort<5,>=4.2.5 in /opt/conda/lib/python3.7/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (4.3.21)\n",
      "Requirement already satisfied: mccabe<0.7,>=0.6 in /opt/conda/lib/python3.7/site-packages (from pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (0.6.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert>=5.3.1->phik>=0.9.8->pandas-profiling) (0.15.7)\n",
      "Requirement already satisfied: wrapt==1.11.* in /opt/conda/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (1.11.2)\n",
      "Requirement already satisfied: lazy-object-proxy==1.4.* in /opt/conda/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (1.4.3)\n",
      "Requirement already satisfied: typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\" in /opt/conda/lib/python3.7/site-packages (from astroid<2.4,>=2.3.0->pylint>=1.4.5->pytest-pylint>=0.13.0->phik>=0.9.8->pandas-profiling) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import gcsfs\n",
    "\n",
    "# setting up file system to be ble to read from buckets\n",
    "\n",
    "fs = gcsfs.GCSFileSystem(project='sm4h-rxspace')\n",
    "\n",
    "now = datetime.now()\n",
    "dt = now.strftime('%Y-%m-%d %H:%M')\n",
    "print(f'start time:\\n{dt}')\n",
    "\n",
    "# pip instlal requirements\n",
    "!pip install pandas==0.25.0;\n",
    "!pip install tqdm==4.33.0;\n",
    "\n",
    "!pip install snorkel;\n",
    "!pip install spacy;\n",
    "!python -m spacy download en_core_web_md;\n",
    "!pip install spacy-lookup;\n",
    "!pip install lemminflect;\n",
    "!pip install pandas-profiling;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing functions and etc\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "from spacy_lookup import Entity\n",
    "from lemminflect import getAllInflectionsOOV\n",
    "from spacy.matcher import Matcher\n",
    "import en_core_web_md\n",
    "import re\n",
    "from snorkel.labeling import labeling_function, LabelModel, PandasLFApplier, LFAnalysis\n",
    "from snorkel.preprocess import preprocessor\n",
    "import io\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train path : gs://sm4h-rxspace/task4/train.csv\n",
      "dev path : gs://sm4h-rxspace/task4/validation.csv\n"
     ]
    }
   ],
   "source": [
    "train_path = \"gs://sm4h-rxspace/task4/train.csv\"\n",
    "dev_path = \"gs://sm4h-rxspace/task4/validation.csv\"\n",
    "print(f'train path : {train_path}\\ndev path : {dev_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train from gs://sm4h-rxspace/task4/train.csv..\n",
      "loaded 10537 samples\n",
      "\n",
      "   class counts  class %\n",
      "m  5488          52.08  \n",
      "c  2940          27.90  \n",
      "a  1685          15.99  \n",
      "u  424           4.02   \n"
     ]
    }
   ],
   "source": [
    "def get_distribution(df, col='class'):\n",
    "    \"\"\"gives distribution of a column \"\"\"\n",
    "    df_out = df[col].value_counts()\n",
    "    n_train = df.shape[0]\n",
    "    print(f\"loaded {n_train} samples\\n\")\n",
    "\n",
    "    df_out = pd.DataFrame(df_out)\n",
    "    df_out.columns = ['class counts']\n",
    "    df_out['class %'] = round(100 * df_out['class counts'] / n_train, 2)\n",
    "    return df_out\n",
    "\n",
    "df_raw = pd.read_csv(train_path)\n",
    "df_raw['class'] = df_raw['class'].map(str.strip) # some labels have a trailing space\n",
    "df_train = df_raw[['unprocessed_text']].rename(columns={'unprocessed_text':'text'})\n",
    "df_labels = df_raw[['class']]\n",
    "\n",
    "print(f'loading train from {train_path}..')\n",
    "\n",
    "print(get_distribution(df_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dev from gs://sm4h-rxspace/task4/validation.csv..\n",
      "loaded 2635 samples\n",
      "\n",
      "   class counts  class %\n",
      "m  1353          51.35  \n",
      "c  730           27.70  \n",
      "a  448           17.00  \n",
      "u  104           3.95   \n"
     ]
    }
   ],
   "source": [
    "df_val_raw = pd.read_csv(dev_path)\n",
    "df_val_raw['class'] = df_val_raw['class'].map(str.strip)\n",
    "\n",
    "df_val = df_val_raw[['unprocessed_text']].rename(columns={'unprocessed_text':'text'})\n",
    "df_val_labels = df_val_raw[['class']]\n",
    "print(f'loading dev from {dev_path}..')\n",
    "print(get_distribution(df_val_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading bseline spacy model\n",
    "nlp = en_core_web_md.load()\n",
    "\n",
    "ABSTAIN = -1\n",
    "ABUSE = 0\n",
    "MENTION = 1\n",
    "CONSUMPTION = 2\n",
    "UNRELATED = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : add Whitley and Mark's drug list into the drugs dictionary\n",
    "# drugname, is_slang, is_commonly_abused\n",
    "drugs = {\n",
    "    'alprazolam' : {\n",
    "        'is_commonly_abused' : True,\n",
    "        'slang_terms' : [\n",
    "            'xanny', 'xannies'],\n",
    "        'normal_terms' : [\n",
    "            'xanax', 'xan', 'xanex', 'niravam'],\n",
    "    },\n",
    "    'codeine' : {\n",
    "        'is_commonly_abused' : True,\n",
    "        'slang_terms' : [],\n",
    "        'normal_terms' : [\n",
    "            'codeine', 'codiene', 'cocet'],\n",
    "    },\n",
    "    'adderall' : {\n",
    "        'is_commonly_abused' : True,\n",
    "        'slang_terms' : [\n",
    "            'addy', 'addies', 'addys'],\n",
    "        'normal_terms' : [\n",
    "            'adderall', 'aderall', 'adarall', 'addarall', 'adoral'],\n",
    "    },\n",
    "    'valium' : {\n",
    "        'is_commonly_abused' : False,\n",
    "        'slang_terms' : [],\n",
    "        'normal_terms' : [\n",
    "            'valium', 'vallium'],\n",
    "    },\n",
    "    'vyvanse' : {\n",
    "        'is_commonly_abused' : True,\n",
    "        'slang_terms' : [],\n",
    "        'normal_terms' : [\n",
    "            'vyvanse'],\n",
    "    },\n",
    "    'fentanyl' : {\n",
    "        'is_commonly_abused' : True,\n",
    "        'slang_terms' : [],\n",
    "        'normal_terms' : [\n",
    "            'fentanyl', 'fentynyl', 'fentenyl', 'fentanil', 'abstral', \n",
    "            'actiq', 'fentora', 'onsolis', 'sublimaze', 'duragesic'],\n",
    "    },\n",
    "    'oxycodone' : {\n",
    "        'is_commonly_abused' : True,\n",
    "        'slang_terms' : ['oxy'],\n",
    "        'normal_terms' : [\n",
    "            'oxycodone', 'oxaydo', 'xtampza', 'oxycontin', 'oxycotin', 'oxycodin'],\n",
    "    },\n",
    "    'hydrocodone' : {\n",
    "        'is_commonly_abused' : True,\n",
    "        'slang_terms' : [],\n",
    "        'normal_terms' : [\n",
    "            'hydrocodone', 'hysingla', 'zohydro', 'vicodin', 'hycet',\n",
    "            'lorcet', 'lortab', 'norco', 'verdrocet', 'xodol'],\n",
    "    },\n",
    "    'methadone' : {\n",
    "        'is_commonly_abused' : False,\n",
    "        'slang_terms' : [],\n",
    "        'normal_terms' : [\n",
    "            'methadone', 'dolophine', 'methadose'],\n",
    "    },\n",
    "    'morphine' : {'is_commonly_abused' : True,\n",
    "                  'slang_terms' : [],\n",
    "                  'normal_terms' : ['morphine', 'avinza', 'oramorph', 'roxanol', 'rms'],\n",
    "                },\n",
    "    'diazepam' : {'is_commonly_abused' : True,\n",
    "                  'slang_terms' : [],\n",
    "                  'normal_terms' : ['diazepam', 'valium'],\n",
    "            },\n",
    "    'tramadol' : {'is_commonly_abused' : False,\n",
    "                  'slang_terms' : [],\n",
    "                  'normal_terms' : ['tramadol', 'ultram'],\n",
    "            },\n",
    "    'quetiapine' : {'is_commonly_abused' : False,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['quetiapine', 'seroquel'],\n",
    "            },\n",
    "    'lorazepam' : {'is_commonly_abused' : False,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['lorazepam', 'ativan'],\n",
    "            },\n",
    "    'clonazepam' : {'is_commonly_abused' : True,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['clonazepam', 'klonopin'],\n",
    "            },\n",
    "    'percocet' : {'is_commonly_abused' : True,\n",
    "                  'slang_terms' : ['percs', 'perc'],\n",
    "                  'normal_terms' : ['percocet', 'percacet', 'percicet'],\n",
    "            },\n",
    "    'aripiprazole' : {'is_commonly_abused' : False,\n",
    "                      'slang_terms' : [],\n",
    "                      'normal_terms' : ['aripiprazole', 'abilify'],\n",
    "            },\n",
    "    'buprenorphine' : {'is_commonly_abused' : False,\n",
    "                       'slang_terms' : [],\n",
    "                       'normal_terms' : ['buprenorphine', 'suboxone', 'naloxone', 'bunavail', 'zubsolv'],\n",
    "            },\n",
    "    'olanzapine' : {'is_commonly_abused' : False,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['olanzapine', 'zyprexa', 'zydis'],\n",
    "            },\n",
    "    'methylphenidate' : {'is_commonly_abused' : True,\n",
    "                         'slang_terms' : [],\n",
    "                         'normal_terms' : ['methylphenidate', 'aptensio', 'concerta', 'cotempla', 'metadate',\n",
    "                                           'methylin',  'quillichew', 'quillivant', 'ritalin'],\n",
    "            },\n",
    "    'risperidone' : {'is_commonly_abused' : False,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['risperidone ', 'risperdal'],\n",
    "            },\n",
    "    'caffeine' : {'is_commonly_abused' : False,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['caffeine', 'caffiene', 'coffee'],\n",
    "            },\n",
    "    'amphetamine' : {'is_commonly_abused' : False,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['amphetamine', 'adzenys', 'dyanavel'],\n",
    "            },\n",
    "    'hydromorphone' : {'is_commonly_abused' : False,\n",
    "                    'slang_terms' : [],\n",
    "                    'normal_terms' : ['hydromorphone', 'dilaudid', 'exalgo', 'hydrostat'],\n",
    "            },\n",
    "}\n",
    "\n",
    "\n",
    "verbs_slang = {'snort', 'crush', 'inject', 'pop', 'rail', 'sniff', 'trip', 'chug'\n",
    "               'spill', 'binge', 'sling', 'slang', 'snortin'}\n",
    "\n",
    "\n",
    "\n",
    "# generate dict that maps terms to keys and values includ parent term, is_slang, is_commonly_abused\n",
    "drug_term_LUT = {}\n",
    "\n",
    "for parent_term, subdict in drugs.items():\n",
    "    for slang_term in subdict['slang_terms']:\n",
    "        drug_term_LUT[slang_term] = {\n",
    "        'parent_term' : parent_term,\n",
    "        'is_slang' : True,\n",
    "        'is_commonly_abused' : subdict['is_commonly_abused']\n",
    "    }\n",
    "        \n",
    "    for normal_term in subdict['normal_terms']:\n",
    "        drug_term_LUT[normal_term] = {\n",
    "        'parent_term' : parent_term,\n",
    "        'is_slang' : False,\n",
    "        'is_commonly_abused' : subdict['is_commonly_abused']\n",
    "    }\n",
    "\n",
    "# creating pipes\n",
    "drug_entity_pipe = Entity(keywords_list=list(drug_term_LUT.keys()), label='DRUG')\n",
    "nlp.add_pipe(drug_entity_pipe, before='ner')\n",
    "\n",
    "has_drug_term = lambda doc : any([True for ent in doc.ents if ent.label_ == 'DRUG'])\n",
    "has_slang_drug_term = lambda doc : any([ent._.get('is_slang') for ent in doc.ents if ent.label_ == 'DRUG'])\n",
    "has_commonly_abused_drug_term = lambda doc : any([ent._.get('is_commonly_abused') for ent in doc.ents if ent.label_ == 'DRUG'])\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def nlpify(x):\n",
    "    # preprocessor gets the series obj, so extract string\n",
    "    doc = nlp(x['text'])\n",
    "    Span.set_extension('is_commonly_abused', default=False, force=True)\n",
    "    Span.set_extension('is_slang', default=False, force=True)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'DRUG':\n",
    "            ent._.set('is_commonly_abused', drug_term_LUT[ent.text.lower()]['is_commonly_abused'])\n",
    "            ent._.set('is_slang', drug_term_LUT[ent.text.lower()]['is_slang'])\n",
    "            # for token in ent:\n",
    "            #   token._.set('is_commonly_abused', drug_term_LUT[ent.text]['is_commonly_abused'])\n",
    "            #   token._.set('is_slang', drug_term_LUT[ent.text]['is_slang'])\n",
    "    Doc.set_extension('has_drug_term', getter=has_drug_term, force=True)\n",
    "    Doc.set_extension('has_commonly_abused_drug_term', getter=has_commonly_abused_drug_term, force=True)\n",
    "    Doc.set_extension('has_slang_drug_term', getter=has_slang_drug_term, force=True)\n",
    "    return doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling fxns\n",
    "@labeling_function(pre=[nlpify])\n",
    "def drug_with_slang_usage(doc):\n",
    "    '''check if drug name in text and mention of abusive use'''\n",
    "    if doc._.has_drug_term:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'DRUG':\n",
    "                head = [t for t in ent][0].head  # get head of the drug entity\n",
    "                if head.pos_ == 'VERB' and head.lemma_ in verbs_slang:\n",
    "                    return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def no_drugnames_found(doc):\n",
    "    '''Check if no drugnames were found'''\n",
    "    if not doc._.has_drug_term:\n",
    "        return UNRELATED\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def slang_drug_with_usage(doc):\n",
    "    '''check if a commonly abused drugname and there's a verb associated with it'''\n",
    "    if doc._.has_slang_drug_term:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'DRUG' and ent._.is_slang:\n",
    "                head = [t for t in ent][0].head  # get head of the drug entity\n",
    "                if head.pos_ == 'VERB':\n",
    "                    return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def normal_drug_with_usage(doc):\n",
    "    '''check if a normal drugname and there's a non-slang verb associated with it'''\n",
    "    if doc._.has_drug_term:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'DRUG' and not ent._.is_slang:\n",
    "                head = [t for t in ent][0].head  # get head of the drug entity\n",
    "                if head.pos_ == 'VERB' and head.lemma_ not in verbs_slang:\n",
    "                    return CONSUMPTION\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def slang_side_effects(doc):\n",
    "    '''Drug mentioned and slang mention of a side effect'''\n",
    "    effect_regexes = [\n",
    "        'fuck(ed)? (me )?up',\n",
    "        'fuck(ed)? with'\n",
    "        'lit(ty)?',\n",
    "        'high',\n",
    "        'od', 'oveerdose(d)?',\n",
    "        'addict(ed|ing)?',\n",
    "        'hooked',\n",
    "        'habit',\n",
    "        'mellow',\n",
    "        'doped',\n",
    "        'hallucinat(e)?(d|ing)?',\n",
    "        'trip(ping)?',\n",
    "        'rollin(g)?',\n",
    "        'buzz(ed)?'\n",
    "        ]\n",
    "    if doc._.has_drug_term and re.search('|'.join(effect_regexes), doc.text.lower()):\n",
    "        return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def drug_with_no_usage(doc):\n",
    "    '''Drug mentioned but not in the context of being used'''\n",
    "    if doc._.has_drug_term:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'DRUG':\n",
    "                head = [t for t in ent][0].head  # get head of the drug entity\n",
    "                if head.pos_ == 'VERB':\n",
    "                    return ABSTAIN\n",
    "    return MENTION\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def clinical_terms(doc):\n",
    "    '''Drug mentioned but with cclinical terms around it'''\n",
    "    medical_terms = {\n",
    "        'doctor', 'nurse'  # TODO : add more medicl terms that indicate typical usage\n",
    "        }\n",
    "    medical_regex = r'(doctor|nurse|(re(- )?)?admi(t|ssion)(s)?|hospital)'\n",
    "    if doc._.has_drug_term and medical_terms.intersection(set([t for t in doc])):\n",
    "        return CONSUMPTION\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def abusive_activities(doc):\n",
    "    ''' drug usage mentioned for the purposes of unintended use '''\n",
    "    activities = {\n",
    "        'adderall': ['clean', 'study'],\n",
    "        'vyvanse': ['study']\n",
    "        }\n",
    "    if doc._.has_drug_term:\n",
    "        for ent in [ent for ent in doc.ents if ent.label_ == 'DRUG']:\n",
    "            drug = drug_term_LUT.get(ent.text.lower())\n",
    "            if drug:\n",
    "                drug_activities = activities.get(drug['parent_term'])\n",
    "                if drug_activities:\n",
    "                    for token in doc:\n",
    "                        if token.lemma_ in drug_activities:\n",
    "                            return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def study_aid(doc):\n",
    "    ''' drugs being useed speccifically as study aid '''\n",
    "    if doc._.has_drug_term:\n",
    "        study_aid_drugs = {'adderall', 'vyvanse'}\n",
    "        drugs = set([drug_term_LUT.get(ent.label_.lower()) for ent in doc.ents if ent.label_ == 'DRUG'])\n",
    "        if drugs.intersection(study_aid_drugs):\n",
    "            study_regex = r'(wak(e|ing)|study(ing)?|homework|school(s)?|libar(y|ies)|education|class(es)?|semester(' \\\n",
    "                          r's)?|exam(s)?|paper(s)?|campus|essay(s)?|college|uni(versity)?)'\n",
    "            if re.search(study_regex, doc.text.lower()):\n",
    "                return abuse\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def soliciting_drug(doc):\n",
    "    '''Check if there is a regex pattern indicating the persom asking for drug'''\n",
    "    if doc._.has_drug_term:\n",
    "        regex = \"(any ?one|someone|any ?body|who|y'all|I|gonna).*(\" \\\n",
    "                \"steal|stole|get|got|has|had|have|holding|find|found|need(ed)?|want|share).*\"\n",
    "        if re.search(regex, doc.text.lower()):\n",
    "            return ABUSE\n",
    "        other_soliciting_terms = {'hmu', }\n",
    "        if other_soliciting_terms.intersection(set([token.text.lower() for token in doc])):\n",
    "            return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def suspicious_emojis(doc):\n",
    "    '''drug mentioned and has emojis commonly used when mentioning abuse'''\n",
    "    suspicious_emojis = {'üíä', 'üçÅ', 'üçÄ', 'üå¥', 'üå≥', 'üå≤', 'üí®'\n",
    "                                                             '‚ùÑ', '‚õÑ', 'üîë', 'üå®', 'üçö', 'ü§ß', 'üé±',\n",
    "                         'üíâ', 'üéØ', 'üêâ', 'üçÑ', }  # TODO add more suspicious emojis\n",
    "    if doc._.has_drug_term and suspicious_emojis.intersection(set([t for t in doc])):\n",
    "        return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def expected_usage(doc):\n",
    "    '''check for each drug mentioned whether theres a mention of a term commonly associated with expected usage'''\n",
    "    usage = {\n",
    "        'seroquel': {'sleep', 'insomnia'},  # TODO : add more common drug usage matches\n",
    "        'xanax': {'anxiety'},\n",
    "        }\n",
    "    if doc._.has_drug_term:\n",
    "        token_set = set([t for t in doc])\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == 'DRUG':\n",
    "                if usage.get(ent.text.lower(), set()).intersection(token_set):\n",
    "                    return CONSUMPTION\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def lyrica_as_nondrug(doc):\n",
    "    if 'lyrica' in doc.text.lower() and re.search('(anderson|lhhh|song|ginny|breisha|lgbt(q)?)', doc.text.lower()):\n",
    "        return UNRELATED\n",
    "\n",
    "    with nlp.disable_pipes('entity'):\n",
    "        w_doc = nlp(doc.text)\n",
    "        lyrica_person = False\n",
    "        for ent in w_doc.ents:\n",
    "            if 'lyrica' in ent.text.lower() and ent.label_ == 'PERSON':\n",
    "                lyrica_person = True\n",
    "        if lyrica_person:\n",
    "            found_other_drug_term = False\n",
    "            for ent in doc.ents:\n",
    "                if 'lyrica' not in ent.text.lower() and ent.label_ == 'DRUG':\n",
    "                    found_other_drug_term = True\n",
    "            if not found_other_drug_term:\n",
    "                return UNRELATED\n",
    "\n",
    "    textlist = doc.text.replace('_U', '').lower().split()\n",
    "    if 'lyrica' in textlist:\n",
    "        if len(textlist) < 5:\n",
    "            return UNRELATED\n",
    "        else:\n",
    "            for ent in doc.ents:\n",
    "                if 'lyrica' in ent.text.lower() and ent.label_ != 'DRUG':\n",
    "                    return UNRELATED\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def buy_or_sell(doc):\n",
    "    if doc._.has_drug_term:\n",
    "        lemmas = set([token.lemma_ for token in doc])\n",
    "        if 'buy' or 'sell' in lemmas:\n",
    "            return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def short_tweet(doc):\n",
    "    if doc._.has_drug_term and len(doc.text.split()) <= 5:\n",
    "        return MENTION\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def chill_pill(doc):\n",
    "    '''someone tells another person to take some drug to calm down'''\n",
    "    if doc._.has_drug_term:\n",
    "        found_drugs = set([ent.text.lower() for ent in doc.ents if ent.label_ == 'DRUG'])\n",
    "        if found_drugs:\n",
    "            chill_regex = \"take (a|some)[a-z _-]{0,10}(\" + '|'.join(found_drugs) + ')'\n",
    "            if re.search(chill_regex, doc.text.lower()):\n",
    "                return MENTION\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def drugs_for_sleep(doc):\n",
    "    ''' mentions of drugs used to help sleep '''\n",
    "    if doc._.has_drug_term and re.search(r\"(sleep(ing)?|(good[ ]?)?night)\", doc.text.lower()):\n",
    "        return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def drug_feels_like(doc):\n",
    "    '''someone mentioning one drug is like something else : ampetemine is like adderall'''\n",
    "    if doc._.has_drug_term and re.search(r\"(is|it(\\')?s)[ ,a-z0-9]{,8}(like|similar)\", doc.text.lower()):\n",
    "        return MENTION\n",
    "    return ABSTAIN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO RULES\n",
    "\n",
    "# anything + alchcohol\n",
    "# anyhtin + energy drink\n",
    "\n",
    "# check for drugs that are mentioned in the hashtag, e.g. #aderrall (not captured by nlp?)\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def mixing_drugs(doc):\n",
    "    '''mention of mixing drugs often used in abuse'''\n",
    "    # map to all alias terms\n",
    "    abuse_pairs = [\n",
    "        ('ambien', 'percocet'),\n",
    "        ('adderall', 'alcohol'),\n",
    "        ('adderall', 'coffee'),\n",
    "        ]\n",
    "    if doc._.has_drug_term:\n",
    "        pdrugs = [drug_term_LUT.get(ent.text.lower(), {}).get('parent_term') for ent in doc.ents if\n",
    "                  ent.label_ == 'DRUG']\n",
    "        drugset = set([drug for drug in pdrugs if drug])\n",
    "        if len(drugset) >= 2:\n",
    "            drug_pairs = itertools.combinations(drugset, 2)\n",
    "            for pair in drug_pairs:\n",
    "                if pair in abuse_pairs:\n",
    "                    return ABUSE\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def person_on_rx(doc):\n",
    "    ''' mention where person indicates the drug is and rx'''\n",
    "    if doc._.has_drug_term and not doc._.has_slang_drug_term:\n",
    "        if re.search('(got|have)[ ]+(me|him|her|my) (on|taking|using)', doc.text.lower()):\n",
    "            return CONSUMPTION\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function(pre=[nlpify])\n",
    "def drug_had_me(doc):\n",
    "    ''' adderall had me ..., indicating side effect of normal use'''\n",
    "    if doc._.has_drug_term:\n",
    "        for ent in [ent for ent in doc.ents if ent.label_ == 'DRUG']:\n",
    "            if drug_term_LUT.get(ent.text, {}).get('parent_term') in {'adderall', 'vyvanse'}:\n",
    "                idx = doc.text.index(ent.text)\n",
    "                if re.search('^[ ]*(have|has|had|got) (me|her|him|them)', doc.text.lower()[idx + len(ent.text):]):\n",
    "                    return CONSUMPTION\n",
    "    return ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10537/10537 [14:13<00:00, 12.35it/s]\n",
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2635/2635 [03:34<00:00, 12.29it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [drug_with_slang_usage,\n",
    "       no_drugnames_found,\n",
    "       slang_drug_with_usage,\n",
    "       normal_drug_with_usage,\n",
    "       slang_side_effects,\n",
    "       drug_with_no_usage,\n",
    "       clinical_terms,\n",
    "       abusive_activities,\n",
    "       study_aid,\n",
    "       soliciting_drug,\n",
    "       suspicious_emojis,\n",
    "       expected_usage,\n",
    "       lyrica_as_nondrug,\n",
    "       buy_or_sell,\n",
    "       short_tweet,\n",
    "       chill_pill,\n",
    "       drugs_for_sleep,\n",
    "       drug_feels_like,\n",
    "       mixing_drugs,\n",
    "       person_on_rx,\n",
    "       drug_had_me\n",
    "       ]\n",
    "\n",
    "# appling with pandas LF applier\n",
    "applier = PandasLFApplier(lfs)\n",
    "# applying to datasets\n",
    "\n",
    "L_train = applier.apply(df_train, progress_bar=True)\n",
    "\n",
    "L_val = applier.apply(df_val, progress_bar=True)\n",
    "\n",
    "class2label = {'a': 0, 'm': 1, 'c': 2, 'u': 3}\n",
    "Y = df_labels['class'].map(lambda x: class2label[x]).to_numpy()\n",
    "\n",
    "Y_val = df_val_labels['class'].map(lambda x: class2label[x]).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drug_with_slang_usage</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.016893</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>76</td>\n",
       "      <td>102</td>\n",
       "      <td>0.426966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_drugnames_found</th>\n",
       "      <td>1</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>0.074689</td>\n",
       "      <td>329</td>\n",
       "      <td>458</td>\n",
       "      <td>0.418043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_drug_with_usage</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.002278</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_drug_with_usage</th>\n",
       "      <td>3</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.454589</td>\n",
       "      <td>0.454589</td>\n",
       "      <td>0.454589</td>\n",
       "      <td>1581</td>\n",
       "      <td>3209</td>\n",
       "      <td>0.330063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_side_effects</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.225871</td>\n",
       "      <td>0.225871</td>\n",
       "      <td>0.222169</td>\n",
       "      <td>440</td>\n",
       "      <td>1940</td>\n",
       "      <td>0.184874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug_with_no_usage</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.527285</td>\n",
       "      <td>0.527285</td>\n",
       "      <td>0.527285</td>\n",
       "      <td>3003</td>\n",
       "      <td>2553</td>\n",
       "      <td>0.540497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical_terms</th>\n",
       "      <td>6</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abusive_activities</th>\n",
       "      <td>7</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.007308</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>0.569620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study_aid</th>\n",
       "      <td>8</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soliciting_drug</th>\n",
       "      <td>9</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.029515</td>\n",
       "      <td>0.029515</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>94</td>\n",
       "      <td>217</td>\n",
       "      <td>0.302251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suspicious_emojis</th>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_usage</th>\n",
       "      <td>11</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyrica_as_nondrug</th>\n",
       "      <td>12</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>0.025055</td>\n",
       "      <td>215</td>\n",
       "      <td>49</td>\n",
       "      <td>0.814394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_or_sell</th>\n",
       "      <td>13</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.925311</td>\n",
       "      <td>0.907564</td>\n",
       "      <td>1666</td>\n",
       "      <td>8084</td>\n",
       "      <td>0.170872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_tweet</th>\n",
       "      <td>14</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>0.051912</td>\n",
       "      <td>350</td>\n",
       "      <td>197</td>\n",
       "      <td>0.639854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chill_pill</th>\n",
       "      <td>15</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>0.018316</td>\n",
       "      <td>114</td>\n",
       "      <td>79</td>\n",
       "      <td>0.590674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugs_for_sleep</th>\n",
       "      <td>16</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.066622</td>\n",
       "      <td>0.066622</td>\n",
       "      <td>0.065199</td>\n",
       "      <td>175</td>\n",
       "      <td>527</td>\n",
       "      <td>0.249288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug_feels_like</th>\n",
       "      <td>17</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>0.707865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixing_drugs</th>\n",
       "      <td>18</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_on_rx</th>\n",
       "      <td>19</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug_had_me</th>\n",
       "      <td>20</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>0.009490</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "drug_with_slang_usage   0   [0]      0.016893  0.016893  0.000949   76        \n",
       "no_drugnames_found      1   [3]      0.074689  0.074689  0.074689   329       \n",
       "slang_drug_with_usage   2   [0]      0.002278  0.002278  0.000475   4         \n",
       "normal_drug_with_usage  3   [2]      0.454589  0.454589  0.454589   1581      \n",
       "slang_side_effects      4   [0]      0.225871  0.225871  0.222169   440       \n",
       "drug_with_no_usage      5   [1]      0.527285  0.527285  0.527285   3003      \n",
       "clinical_terms          6   []       0.000000  0.000000  0.000000   0         \n",
       "abusive_activities      7   [0]      0.007497  0.007497  0.007308   45        \n",
       "study_aid               8   []       0.000000  0.000000  0.000000   0         \n",
       "soliciting_drug         9   [0]      0.029515  0.029515  0.029230   94        \n",
       "suspicious_emojis       10  []       0.000000  0.000000  0.000000   0         \n",
       "expected_usage          11  []       0.000000  0.000000  0.000000   0         \n",
       "lyrica_as_nondrug       12  [3]      0.025055  0.025055  0.025055   215       \n",
       "buy_or_sell             13  [0]      0.925311  0.925311  0.907564   1666      \n",
       "short_tweet             14  [1]      0.051912  0.051912  0.051912   350       \n",
       "chill_pill              15  [1]      0.018316  0.018316  0.018316   114       \n",
       "drugs_for_sleep         16  [0]      0.066622  0.066622  0.065199   175       \n",
       "drug_feels_like         17  [1]      0.008446  0.008446  0.008446   63        \n",
       "mixing_drugs            18  []       0.000000  0.000000  0.000000   0         \n",
       "person_on_rx            19  [2]      0.000759  0.000759  0.000759   5         \n",
       "drug_had_me             20  [2]      0.009490  0.009490  0.009490   72        \n",
       "\n",
       "                        Incorrect  Emp. Acc.  \n",
       "drug_with_slang_usage   102        0.426966   \n",
       "no_drugnames_found      458        0.418043   \n",
       "slang_drug_with_usage   20         0.166667   \n",
       "normal_drug_with_usage  3209       0.330063   \n",
       "slang_side_effects      1940       0.184874   \n",
       "drug_with_no_usage      2553       0.540497   \n",
       "clinical_terms          0          0.000000   \n",
       "abusive_activities      34         0.569620   \n",
       "study_aid               0          0.000000   \n",
       "soliciting_drug         217        0.302251   \n",
       "suspicious_emojis       0          0.000000   \n",
       "expected_usage          0          0.000000   \n",
       "lyrica_as_nondrug       49         0.814394   \n",
       "buy_or_sell             8084       0.170872   \n",
       "short_tweet             197        0.639854   \n",
       "chill_pill              79         0.590674   \n",
       "drugs_for_sleep         527        0.249288   \n",
       "drug_feels_like         26         0.707865   \n",
       "mixing_drugs            0          0.000000   \n",
       "person_on_rx            3          0.625000   \n",
       "drug_had_me             28         0.720000   "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## summary anlysis \n",
    "summary_analysis = LFAnalysis(L_train, lfs).lf_summary(Y)\n",
    "summary_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/snorkel/labeling/model/label_model.py:378: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.clip(accs / self.coverage, 1e-6, 1.0)\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>drug_with_slang_usage</th>\n",
       "      <td>0</td>\n",
       "      <td>0.591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_drugnames_found</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_drug_with_usage</th>\n",
       "      <td>2</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>normal_drug_with_usage</th>\n",
       "      <td>3</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slang_side_effects</th>\n",
       "      <td>4</td>\n",
       "      <td>0.484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug_with_no_usage</th>\n",
       "      <td>5</td>\n",
       "      <td>0.474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical_terms</th>\n",
       "      <td>6</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abusive_activities</th>\n",
       "      <td>7</td>\n",
       "      <td>0.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study_aid</th>\n",
       "      <td>8</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soliciting_drug</th>\n",
       "      <td>9</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suspicious_emojis</th>\n",
       "      <td>10</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_usage</th>\n",
       "      <td>11</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lyrica_as_nondrug</th>\n",
       "      <td>12</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_or_sell</th>\n",
       "      <td>13</td>\n",
       "      <td>0.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_tweet</th>\n",
       "      <td>14</td>\n",
       "      <td>0.470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chill_pill</th>\n",
       "      <td>15</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drugs_for_sleep</th>\n",
       "      <td>16</td>\n",
       "      <td>0.401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug_feels_like</th>\n",
       "      <td>17</td>\n",
       "      <td>0.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mixing_drugs</th>\n",
       "      <td>18</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_on_rx</th>\n",
       "      <td>19</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drug_had_me</th>\n",
       "      <td>20</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         j      w\n",
       "drug_with_slang_usage   0   0.591\n",
       "no_drugnames_found      1   1.000\n",
       "slang_drug_with_usage   2   0.828\n",
       "normal_drug_with_usage  3   0.550\n",
       "slang_side_effects      4   0.484\n",
       "drug_with_no_usage      5   0.474\n",
       "clinical_terms          6   1.000\n",
       "abusive_activities      7   0.154\n",
       "study_aid               8   1.000\n",
       "soliciting_drug         9   0.435\n",
       "suspicious_emojis       10  1.000\n",
       "expected_usage          11  1.000\n",
       "lyrica_as_nondrug       12  1.000\n",
       "buy_or_sell             13  0.270\n",
       "short_tweet             14  0.470\n",
       "chill_pill              15  0.108\n",
       "drugs_for_sleep         16  0.401\n",
       "drug_feels_like         17  0.381\n",
       "mixing_drugs            18  1.000\n",
       "person_on_rx            19  0.013\n",
       "drug_had_me             20  0.776"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_model = LabelModel(cardinality=4, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=500, log_freq=50, seed=123)  # , class_balance=[.15, .5, .3, .05]);\n",
    "df_train[\"label\"] = label_model.predict(L=L_train, tie_break_policy=\"abstain\")\n",
    "df_val[\"label\"] = label_model.predict(L=L_val, tie_break_policy=\"abstain\")\n",
    "# looking at weights\n",
    "weights = summary_analysis[['j']]\n",
    "weights['w'] = [round(w, 3) for w in label_model.get_weights()]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# organizing data\n",
    "df_train['groundtruth'] = df_labels['class']\n",
    "df_train['predicted_class'] = df_train['label'].map({-1: None, 0: 'a', 1: 'm', 2: 'c', 3: 'u'})\n",
    "df_train['correct?'] = df_train['groundtruth'] == df_train['predicted_class']\n",
    "\n",
    "df_val['groundtruth'] = df_val_labels['class']\n",
    "df_val['predicted_class'] = df_val['label'].map({-1: None, 0: 'a', 1: 'm', 2: 'c', 3: 'u'})\n",
    "df_val['correct?'] = df_val['groundtruth'] == df_val['predicted_class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n",
      "WARNING:root:Metrics calculated over data points with non-abstain labels only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Data Performance\n",
      "Model F1 Macro            40.3%\n",
      "Model F1 Micro:           38.8%\n",
      "\n",
      "\n",
      "Validation Data Performance\n",
      "Model F1 Macro            40.6%\n",
      "Model F1 Micro:           39.0%\n"
     ]
    }
   ],
   "source": [
    "acc_train = label_model.score(L=L_train, Y=Y, tie_break_policy=\"abstain\",\n",
    "                              metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\"])\n",
    "print('\\nTraining Data Performance')\n",
    "print(f\"{'Model F1 Macro':<25} {acc_train['f1_macro'] * 100:.1f}%\")\n",
    "print(f\"{'Model F1 Micro:':<25} {acc_train['f1_micro'] * 100:.1f}%\")\n",
    "\n",
    "acc_val = label_model.score(L=L_val, Y=Y_val, tie_break_policy=\"abstain\",\n",
    "                            metrics=[\"f1_macro\", \"f1_micro\", \"accuracy\"])\n",
    "print('\\n\\nValidation Data Performance')\n",
    "print(f\"{'Model F1 Macro':<25} {acc_val['f1_macro'] * 100:.1f}%\")\n",
    "print(f\"{'Model F1 Micro:':<25} {acc_val['f1_micro'] * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_ = ['a', 'c', 'm', 'u']\n",
    "cmat = confusion_matrix(df_train['groundtruth'][~pd.isnull(df_train['predicted_class'])],\n",
    "                        df_train['predicted_class'][~pd.isnull(df_train['predicted_class'])],\n",
    "                        labels=labels_)\n",
    "df_cmat = pd.DataFrame(cmat.T, labels_, labels_)\n",
    "sn.set(font_scale=1)  # for label size\n",
    "sn.heatmap(df_cmat, annot=True, annot_kws={\"size\": 10}, fmt='d', cbar=False,\n",
    "           cmap='RdBu', center=0, square=True)  # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAciklEQVR4nO3deVxU9f7H8deZGUY22cEFTVDUFEvRck9zScXUNKmuZaVl5pZaWlqWZVmW160oNbNrLmlZ3nJPy+utVCD33E0NwwXZ921mOL8/qOn6Kw0MOOL383w8fDyY78w47y/Mm+85Z/QcTdd1HSHEDc9kdAAhROWQsguhCCm7EIqQsguhCCm7EIqQsguhCEtlvtjm45cq8+UqzcnUXKMjVIg9P6cZHaFCLIpqZnSECuPm6nrF+2RlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRlXp22fKy8p03ObpnF57evkyOXnrZff/5YhXrPlrA9OXr8PTywW6zsXr+LBJOH0fTTAwYNpaGt0QYlPzqstOS2bZ4FnmZ6WiaRtPOkTS/qz8FOdlsXTiD7JRLVA+oQY+Rz+PqUR2H3ca3S6NJiv8JTdPo+OAIgm++1ehp/Ck/dxeebB+Kt5sLug7bf0pm64kkRnesTy2vkjOiulvN5BU5eHHTUcwmjcfa1CPUzx0dWL4ngeOXso2dxDWIjIzEw90dk9mMxWxm5apVhmWpkmVv060Xd9w9gI/nvXHZeHryJU4c2INvYA3nWMzW9QBMemcp2RnpvP/qszwzaxEm0/W3UWMymenwwBME1gujKD+Pz14dS92mERzf+Q11mrSg5d33s2/javZvWk27+x7n6LdfAfCP1xaQl5XBxrkvEfXS22jX4dwcOqzcd46zaXm4Wky82rsphxOzeG/HGedjBrWsQ77NAUCXsAAAXth4FK9qFiZ2bcjLm49RFS85/MHixfj6+hodo2puxjcIb4G7p9cfxr/88F36DRkJmuYcu5QQT6PmrQCo7uOLm4cnCaeOV1rWsvDw8SOwXhgAVjd3fGvVJTcjlfj9MTTu0B2Axh268/O+GADSL/xCcNMWALh7+WB19yAp/idjwv+FzHwbZ9PyACiwF3MhMx8/N+tlj2lTz4+Y+JJz1Qd7u3EkMQuArEI7eUUOQv09Kjf0DaZUK3t2djYffPABx44do7Cw0Dm+bNmyCgtWVofjduDtH0BwaNhl47VDwzgUt4OIO7qSkZJEwumTZKQkUa9RU4OSlk5WyiVSfjlNjfqNycvKwMPHDyj5hZCfnQmAf91Q4vfH0LB1Z3LSkkmOP0VOWjI16jc2MvpfCvCwUs/PnVOpOc6xxkGeZBbYuJRd8v76JT2PVnV8iI1Pw9/dSoi/O37uLpxJNSr1tdGAkSNGoGkaA6OiiIqKMixLqcr+wgsv0KBBA+Lj4xk3bhxr1qwhPDy8orOVWlFhAVs/W87IabP/cF+b7r25lHCW2ROG4xdYg9CbwzGZzQakLD1bQT5b3ptOh0FPYnW78mrW5I6epF9M4LNXx1LdP4iaYU2u+7lVs5gY26kBH+9JoMBW7BxvF+JHbPzvV6D59nQKtb3deDWyKSm5hZxKzqW4Cm7Df7R0KUFBQaSlpjJixAhCQ0Np1aqVIVlKVfazZ88SHR3Ntm3b6NOnDz169GD48OEVna3UUi6eJy3pIjPHPwZAZkoys54exjOz3sfL158Bw55yPnbecyMJrFXXqKh/yWG389V702nYtgsNWnUASjbRczPS8PDxIzcjDbfq3gCYzGY6DnrS+dw1rz+Dd1BtQ3KXhlnTGNupAbvi09iTkOEcN2lwW11fXtp81DlWrMPHexOct6f2vJnE7IJKzVsegoKCAPDz96dL164cPnzYsLKXap/dai3Zt3JxcSEjIwMXFxcSExMrNFhZ1A5pwPRl63j5g9W8/MFqvAMCmTh3MV6+/hQVFlBYkA/AiQO7MZnN1LwpxNjAV6DrOtuXzMO3Vl1a9LzXOR4S0ZYTO78B4MTObwiJaAeArbAAW2FJARKO7MNkNuMXXK/yg5fSsHb1uJBZwFfHLr/mX3hNLy5mFZCeZ3OOWc0mqplL3p7NanrhKNa5kFm1yp6fl0dubq7z65iYGMLCwv7iWRWnVCt7SEgIGRkZ9O3blwceeIDq1avTpEmTis52RUtnTeP04f3kZGXy8mMDiRw0lLZ39fnTx2ZnpLPwlYloJg0fv0AGP/1iJactvcSfjnAyZht+dUL49OXRALQd+Cgte9/PlgVvcOz7LXj6B9Jz5BQA8rMz2TB7CphMePr4033YRCPjX1WjQE861g/gl/Q8pvcuOV7y2YHzHLyQSbuQ3w/M/cbL1cJz3RpRrOuk59lYuOtnI2L/LalpaTzz9NMA2O12Inv3pkOHDobl0XRdL9Oe0J49e8jOzqZTp06Yy7h/KFdxrVrkKq5Vz9Wu4lrmz9lvu+22vxVGCGGMKvk5uxCi7KTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQihCyi6EIqTsQiiiUi/ZnPfr5XhvNNuPJRkdoUJsem+R0REqxKKo+UZHMISs7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCKk7EIoQsouhCIq9VTS5WXNe29xfG8sHt4+jJ+7xDm+a9O/if3qS0wmE41btSXy4REk/HSML9+fDYCu63S7fwjhbe4wKvpVBXhYGde5AT7uVnRdZ+vxJDYcSSTEz50RHUJxczGTlFPInO2nyP+f03IHeFiJjmrOJ/vOsfbQRQNncHUnN84kJ7cAR3Exdkcx7R56lRnj76NPpxYU2eycOZfMsJc/JDMnH4DnHuvNkHvuoLhY5+mZH/N1zBGDZ1A2hYWFPDZ0KDabDbvdTve77mLUqFGG5amSZW/ZpRdtIwfwWfQM59jpw/s5tnsnY2cvxuJiJSczHYAaN4Uy6q33MZvNZKWnEj1hGDff1h6z2WxU/CtyFOssiTvLmdQ8XF1MzO5/CwfOZzL6jvp8FHeWI4nZdGsUyIBba7Fy7znn8x5vW499CRkGJi+9u4bPJDUjx3l7W+xRXoxeg8NRzBtjo5j02N288M7nNKlfm/t7tqFF1EvUDvRh88KJhPd/nuJi3cD0ZWO1Wvlg8WLc3d2x2WwMHTKEjh07cuuttxqSp1Sb8bt27SI7O9t5Oysri5iYmAoL9VdCmzbH3dPrsrG4LWvpPOBBLC5WADy9fQGwVnN1FtteVASaVrlhyyA938aZ1DwACmzFnMvIx9/DSrC3K0cSS77/B89n0i7Ez/mcNvV8ScwuJCEj35DMf9c3sUdwOIoBiDt0huAaJT+3vne2YPWWOIpsduIvpHA6IYnbm9U3MmqZaZqGu7s7AHa7HbvdjpHvvlKVfebMmXh6ejpve3p6MnPmzAoLdS1SL54j/tiPzJ88kkVTx3Hu1HHnfQknjzJv/BDemfAY/Yc/fV2u6v9fkGc16vt7cDIph1/S82l9U0kJ2of6EeBRDYBqFhMDbq3Np/vOXe2vum7ous6m+ROI/Xgqj9/b+Q/3D7mnI1t2HgKgdqAv5xLTnPedT0onOMin0rKWF4fDwf3330/XLl1o27Yttxi0qkMpy67rOtr/rIgmkwmH4/q6lJPD4SA/J5uRM+YT+fAIVs2Zhq6XbPLVbdSU8fM+YtSbC/n2i5XYiooMTnt1rhYTk7o35MPYePJtDqK/O03vpjWY3b8Zbi5mbMUlK+GglnVYf/giBfZigxOXzp1DZ9DmwWn0HTOXkQ90pWPLRs77Jj/eB7ujmJWbYgEue7/9Rq86W/BOZrOZ1atXs2XrVg4fPsypn34yLEup9tk9PDw4ePAgzZs3B+DgwYPOzZPrhbd/IOFtOqFpGnUbNkHTTORmZeLp/ftqEFSnHi7VXLn0y8/UCWtsYNorM2sak7o34ttTKcTGlxx3OJ9ZwCtflWyp1PZypVXdklW+UZAn7UP9ebR1PTysZop1sDmK2XT0kmH5r+ZicslxheT0bNb+Zx+3h4eyY99JHu7bnt6dbqXnk7Ocjz2flEadmr/vrgQH+XIhuWocl/gzXl5e3Hb77ezctYuwhg0NyVCqsj/77LOMHj2asLAwAE6dOsW7775bocHKquntHTl9eB/1m7Ug5UICDrsNDy9v0i5dxDsgCLPZTHpyIikXEvANqml03Csa06k+5zLyWXc40Tnm7Wohs6Bkf+++iGC2HC8p8wsbjjof84+Wdci3Oa7boru7WjGZTOTkFeDuaqV7u3BeX7SOHu2bMXFIb7oNe4v8gt+3uDb89wDLZjzJvOVbqR3oQ9hNNdh9+IyBMyi7tLQ0LBYLXl5eFBQUEBcby9ChQw3LU6qyR0REsHHjRg4cOICu60RERODt7V3R2a7ok7mv8fORA+RmZ/Lm8Pvo/sAQWnWN5N/zZzLv6aFYLC5EjZmMpmmcPX6Ib79YidliQdNM3PPEeDy8jMt+NU1qVKdLw0Di03KZO+AWAFbsTqCWtyuRTWsAEBufxraTyUbGvCY1/L35bM4YACxmE59sjmPrrsMcXTuDalYXNi+YAEDcodOMeX05R89c4POtuzm4ZjoORzHj3lxRpY7EA6SkpPDSiy9SXFxMcXExPXr0oFPnPx6rqCyarlfentCaQxcq66Uq1fK4X4yOUCFu1Es2Z8bcuJdsdnN1veJ98i/ohFCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRUjZhVCElF0IRVTqVVwD3K2V+XKV5sHWNxkdoUJs+cDN6AgVwl7Fzj9fXmRlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFFGpp5IuLx/NfYNDP+ykuo8vryxYAcDaZYs4ELsDzaRR3duXoc9Mwcc/kJysTBa+MYWzJ4/TrnskD46aYHD6q/ti/luc2BuLh7cPT81Z4hyP3fxvYjd/iclsonHLtvR8eAR2m411i+Zw/vQJNJPG3UOfIjS8hYHpr+74F6+SnVeAo1jH7nDQcchMfL3cWT79MerV9ufshVQGT/mQjOx8ura+mddG34PVYqbI7uCFd77g270njZ7CX5r2ysvs+O47fP38WP35msvuW75sKW/Pncs3/9mOj69vpWerkmVv3703XfoOZMns15xjPaIe4p5HhgOwbe1nbFi5hMFPPYeL1co9Dz/BhfgznD97xqjIpRZxZy/a9BrAmndnOMfOHN7Psd07GTN7MRYXKzmZ6QDs3bYBgKfm/IuczHSWvz6JJ99ciMl0/W6w9Rr1NqmZuc7bEx/pwX/3nGDWsq+Z+MhdTHykBy++t5bUjByiJizkYkomTevXYv3bY2jQd4qByUunb99+PPDAP5j60ouXjScmJhIXG0vNmrUMSlZFN+Mb3dICj+pel425uXs4vy4qyEfTNACqubrRMLw5LtaqcYGKkKbNcfO8fG4/bF1Lp/4PYnEpmYOnd8mqkHTuLPVvaekcc/Xw5MLpE5Ub+G/q0+lWVmyMA2DFxjj6dm4OwMGT57iYkgnA0TMXqVbNgtXl+l+bWrZqhZe31x/G58yaxdhx4/n1bWmI6/+7VwZfLH2f2G1f4ebhwYQ3o42OU25SL5wj/tiPfLOqZGXv+chI6oTdTM16DTi+eye3dOhKVkoSF86cJDM1iToNmxgd+U/p6Kx/Zww68OEXO/jXlzsJ8qtOYmoWAImpWQT6Vv/D8wZ0jeDgiXMU2eyVnLh8fPvf/xIUFEijxo0NzVGqsp85c4YFCxaQkJCA3f77N/zzzz+vsGDXYsCjTzLg0SfZ/Okytq9fQ7/Bw4yOVC6Kix0U5GYz/I35nD91nE/nTOOZ91bSsmtvks//wsJJT+ITWIO6jZthMpuNjntFXZ+Yw8WUTAJ9PdkQ/RQn4i/95XOahNZi+uh76DP23UpIWP4K8vP514eLeW/+AqOjlK7s48aN45577uHee+/FfB2/mX7T+s4eRL8y8YYpu5dfIE3bdELTNOo0bIJmMpGXlYmHtw+9h4x2Pm7RlDH416xjYNKr+22zPDk9h3X/Pcjt4fVISsumpr8XialZ1PT3Ijk92/n44CAfPp35BMOmLePn8ylGxf5bzp07x4Xz5xn0wP0AJCUl8dCDg1i6fAUBAQGVmqVUZbdYLAwbdn0X59L5BGoE1wXgYNz31KxTz+BE5adJ646cObSP0PAWpFxIwGG34e7lTVFhAeg6Vlc3Th3cg8lsJqhuiNFx/5S7qxWTSSMnrxB3Vyvd2zThjQ83s/H7Qwy+uw2zln3N4LvbsOG7HwHw9nTj33NGMnX+OmJ+vP4PrF5JWMOGfP2f7c7bfXtHsvzjldfv0fg77riD7777jk6dOlV0nlL54K2XOfHjfnKyMnju4f70G/w4h3bHcOn8L2iaCf+gmjw05lnn458fMpD8vFwcdjsHYr5n/OtzqX1TqIEzuLLV817j5yMHyMvO5J9P3kfX+4fQskskXyyYSfQzQzFbXBg4ejKappGbmcHS6c+hmTS8/AKIeup5o+NfUZBfdT6dWfJpicVs5tMtu/k69ih7j55lxRuP82i/9iQkpvPQC4sBGHFfZxrUCWTyY5FMfiwSgL5jo0lOzzFsDqXxwuTJ7N27h4yMDHr37MHwESPpP2CA0bEA0HRd/8vr18bExDBq1ChMJhNWqxVd19E0jZiYmDK92Lenq+am2F+5lFtkdIQK8egTrxsdoUIkbZ9ldIQKU939ypfZLtXKPnXqVGbMmEF4ePh1/RmuEOLKSlV2b29vevXqVdFZhBAVqFTLdPfu3Vm1ahUZGRnk5+c7/wghqo5Srezz5s0DYNq0aWia5txnP3bsWIWGE0KUn1KV/fjx4xWdQwhRweRomxCKkLILoQgpuxCKkLILoQgpuxCKkLILoQgpuxCKkLILoQgpuxCKkLILoQgpuxCKkLILoQgpuxCKkLILoQgpuxCKkLILoQgpuxCKKNWppMtLfkFBZb1UpUrOq5rXIPsrZiOvQliBcmwOoyNUmMZBf7yo5G9kZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRQhZRdCEVJ2IRRhMTpARYiMjMTD3R2T2YzFbGblqlVGR7pmgwf0we3XuZjNZuYvWcGpkyd4e+YbFBUVYTabGTtxMjeHNzM6apkM6n837h4emEwmzGYzCz/6mIXRc4nZ8T0uFgu16tRl0ouv4Fm9utFRy2TtpyvZuuFLNE2jXv0wxj0/lY8XL+SHXd9jsbhQK7gOY5+fasi8bsjzxkdGRrJy5Up8fX0r5fUq8rzxgwf04b0ly/H2+X0uk8aNYuA/HqJ1uw7E7drB6hXLmD1/Ubm/dkWeN35Q/7tZ+NGKy+a1Oy6Glq1ux2yxsOjdtwEYPmZcub92RZ03PjU5iUmjn+C95Z9SrZorb019ntvatscvIJBbW96G2WLhowXRAAwZ+VSFZJDzxt9gNE0jLzcXgNycHPwDAgxOVD5ub9MOs6VkY7NJs1tITkoyOFHZFTvsFBUW4rDbKSwowC8gkIjWbZ3zahzejNTkS4ZkK9VmfNu2bdH+5Ld8TExMuQcqDxowcsQINE1jYFQUUVFRRke6ZpqmMXncaDRN4+7+A7m7/72MHD+R58ePZlH0PIqLi3l70RKjY5aZpmk8O3Y0mgZ9BwykT/+Bl92/ef1aunTvYVC6a+MfGET/fwzm8ai+WK3ViGjdhojWbS97zDcb19Gx612G5CtV2desWeP8urCwkPXr12OxXL+7+x8tXUpQUBBpqamMGDGC0NBQWrVqZXSsazL3/X8REBhIeloak8eNom69EL7f/g0jx03gji7d+Pabrcx+41VmRi8wOmqZvLNoiXNez44dSd16ITSPKPkZrViyGLPFQvdevQ1OWTY52VnE7fiODz5di0f16rz10mS2b9lEl54l81i97F+YzRbu7BFpSL5SbcYHBwc7/9SvX59x48YRFxdX0dmuWVBQEAB+/v506dqVw4cPG5zo2gUEBgLg6+dHh85dOHH0MFs3baDjnV0B6NTtLk4cPWJkxGvyv/Pq2LkLx3+dw5aN64nd+T1Tpk3/063J69mBPT9Qo1ZtvH19sVgstOvcheOHfwRg2+YN7N61gwlTXzNsXte0z56QkMD58+fLO0u5yM/LI/fX/dn8vDxiYmIICwszONW1yc/Pd+6b5+fnszculpD6YfgHBPLj/r0A7N+zm+C6dY2MWWb/f157fogltH4DfojZySfLP2L6P+fh6upmcMqyCwyqyYkjhygsKEDXdQ7u3U3deqHsjdvFvz9exoszZlPN1dWwfGXeZy8uLsZutzNlypQKDXatUtPSeObppwGw2+1E9u5Nhw4dDE51bTLSUnll8kQAHA4HXXr04vZ27XFzd2P+3Fk4HA6sVivjJ79ocNKySU9LZeqkCUDJvLr16EXrdh0YHNUPW5GNZ8eOBKBps1t4etL1+T77M43Dm9Hhzm6Mf3wwZrOZ+g0b07PfAEY/8gB2WxFTnxn96+NuYdTE5ys9X6k+evvfVdxisRAQEIDZbC7zi8klm6sWuWRz1XO1j95KtbIHBweXWxghhDHkc3YhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRlXrJZiGEcWRlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRUnYhFCFlF0IRN1zZJ0yYwL333kvfvn0ZPXo0mZmZRkcqN/v372fQoEH069ePfv36sWPHDqMjXbPGjRuzYMECBg4cSLdu3YiJiWH27Nn079+fPn36cPr0aaMj/i3nzp2jTZs2V7xtCP0Gk5qa6vx6zpw5+j//+U8D05Sf9PR0vX379vrevXt1Xdd1u92uZ2RkGJzq2jVq1EhfsWKFruu6vmnTJr1Fixb69u3bdV3X9UWLFukTJkwwMN3fl5CQoLdu3fqKt41gMfZXTflbu3Yt69evx2azkZeXR0hIiNGRysWBAwdo0KABLVu2BMBsNuPt7W1wqr8nMjISgPDwcADuvPNOAJo1a8bXX39tVKwb1g1V9j179rBq1So++eQT/Pz8WL9+PatXrzY6VrnQb8D/iVytWjUATCYTVqvVOW4ymbDb7UbFKhcWi+Wyn1lhYaGBaUrcUPvsWVlZeHp64uPjQ1FREWvWrDE6UrmJiIjg9OnT7N+/HwCHw3FDHY+40QQEBGCz2Th79iwAGzZsMDjRDbayd+rUiXXr1hEZGUmNGjVo1qwZhw4dMjpWufDx8SE6Opo333yTvLw8TCYTkyZNon379kZHE3/CYrEwZcoUhg4dSnBwsPEH55Az1QihjBtqM14IcWVSdiEUIWUXQhFSdiEUIWUXQhFSdiEUIWUXQhFSdiEU8X+glHLwSYv1tAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmat = confusion_matrix(df_val['groundtruth'][~pd.isnull(df_val['predicted_class'])],\n",
    "                        df_val['predicted_class'][~pd.isnull(df_val['predicted_class'])],\n",
    "                        labels=labels_)\n",
    "df_cmat = pd.DataFrame(cmat.T, labels_, labels_)\n",
    "sn.set(font_scale=1)  # for label size\n",
    "sn.heatmap(df_cmat, annot=True, annot_kws={\"size\": 10}, fmt='d', cbar=False,\n",
    "           cmap='RdBu', center=0, square=True)  # font size\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_class\n",
       "a    2732\n",
       "c    3750\n",
       "m    3265\n",
       "u    790 \n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('groundtruth')['text'].count()\n",
    "\n",
    "df_train.groupby('predicted_class')['text'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           a       0.23      0.33      0.27       448\n",
      "           c       0.30      0.40      0.34       730\n",
      "           m       0.62      0.37      0.46      1353\n",
      "           u       0.42      0.79      0.54       104\n",
      "\n",
      "    accuracy                           0.39      2635\n",
      "   macro avg       0.39      0.47      0.41      2635\n",
      "weighted avg       0.45      0.39      0.40      2635\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sklm\n",
    "\n",
    "print(sklm.classification_report(y_true=df_val['groundtruth'][~pd.isnull(df_val['predicted_class'])],\n",
    "                        y_pred = df_val['predicted_class'][~pd.isnull(df_val['predicted_class'])],\n",
    "                        labels=labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>_U _U _U yeah &amp; i have xanax &amp;painkillers to help me lol my ankle is still f'ed..wore tennis shoes &amp; brace</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>pop an adderall i'm  sweatin wooooüòé</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1799</th>\n",
       "      <td>Pretty pissed that I was on morphine and tramadol for weeks when I was sick and I never tripped, not once</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3682</th>\n",
       "      <td>_U that's what i say every time i don't take my adderall</td>\n",
       "      <td>2</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8049</th>\n",
       "      <td>_U xanax is garbage.</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>c</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1658</th>\n",
       "      <td>the amount of seroquel i'm on could probably tranquilize a horse</td>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>m</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4101</th>\n",
       "      <td>_U in between shots i take lyrica  and bacfolan</td>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>u</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            text  \\\n",
       "2196  _U _U _U yeah & i have xanax &painkillers to help me lol my ankle is still f'ed..wore tennis shoes & brace   \n",
       "34    pop an adderall i'm  sweatin wooooüòé                                                                          \n",
       "1799  Pretty pissed that I was on morphine and tramadol for weeks when I was sick and I never tripped, not once    \n",
       "3682  _U that's what i say every time i don't take my adderall                                                     \n",
       "8049  _U xanax is garbage.                                                                                         \n",
       "1658  the amount of seroquel i'm on could probably tranquilize a horse                                             \n",
       "4101  _U in between shots i take lyrica  and bacfolan                                                              \n",
       "\n",
       "      label groundtruth predicted_class  correct?  \n",
       "2196  2      c           c               True      \n",
       "34    0      c           a               False     \n",
       "1799  0      c           a               False     \n",
       "3682  2      c           c               True      \n",
       "8049  2      m           c               False     \n",
       "1658  1      c           m               False     \n",
       "4101  3      c           u               False     "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs = {\n",
    "    'acetaminophen',\n",
    "    'hydrocodone',\n",
    "    'codeine',\n",
    "    'chlorpheniramine',\n",
    "    'morphine',\n",
    "    'buprenorphine',\n",
    "    'hydromorphone',\n",
    "    'butorphanol',\n",
    "    'ipratropium',\n",
    "    'fentanyl',\n",
    "    'oxycodone',\n",
    "    'methadone',\n",
    "    'tramadol',\n",
    "    'aspirin',\n",
    "    'guaifenesin',\n",
    "    'caffeine',\n",
    "    'nalbuphine',\n",
    "    'homatropine',\n",
    "    'remifentanil',\n",
    "    'sufentanil',\n",
    "    'naloxone',\n",
    "    'meperidine',\n",
    "    'dihydrocodeine',\n",
    "    'oxymorphone',\n",
    "    'ibuprofen',\n",
    "    'phenylephrine',\n",
    "    'brompheniramine',\n",
    "    'pseudoephedrine',\n",
    "    'pentazocine',\n",
    "    'butalbital',\n",
    "    'carisoprodol',\n",
    "    'promethazine',\n",
    "    'levorphanol',\n",
    "    'vicodin',\n",
    "    'anexsia',\n",
    "    'lorcet',\n",
    "    'taxadone',\n",
    "    'reprexain',\n",
    "    'dolacet',\n",
    "    'xylon',\n",
    "    'cocet',\n",
    "    'tussicaps',\n",
    "    'kadian',\n",
    "    'subutex',\n",
    "    'dilaudid',\n",
    "    'torbugesic',\n",
    "    'atrovent',\n",
    "    'xodol',\n",
    "    'duragesic',\n",
    "    'norco',\n",
    "    'percocet',\n",
    "    'endocet',\n",
    "    'lynox',\n",
    "    'oramorph',\n",
    "    'dolophine',\n",
    "    'dazidox',\n",
    "    'physeptone',\n",
    "    'ultram',\n",
    "    'roxanol',\n",
    "    'duocet',\n",
    "    'oxynorm',\n",
    "    'actiq',\n",
    "    'lortab',\n",
    "    'nubain',\n",
    "    'ryzolt',\n",
    "    'perloxx',\n",
    "    'morphabond',\n",
    "    'zydol',\n",
    "    'sevredol',\n",
    "    'roxicodone',\n",
    "    'hydrotropine',\n",
    "    'hydromide',\n",
    "    'astramorph',\n",
    "    'ultiva',\n",
    "    'sufenta',\n",
    "    'ionsys',\n",
    "    'tramake',\n",
    "    'oxycontin',\n",
    "    'percodan',\n",
    "    'tylenol',\n",
    "    'suboxone',\n",
    "    'zamadol',\n",
    "    'trezix',\n",
    "    'verdrocet',\n",
    "    'oncet',\n",
    "    'glydeine',\n",
    "    'procet',\n",
    "    'demerol',\n",
    "    'roxicet',\n",
    "    'stadol',\n",
    "    'roxilox',\n",
    "    'endodan',\n",
    "    'maxidone',\n",
    "    'zerlor',\n",
    "    'synalgos-dc',\n",
    "    'combunox',\n",
    "    'panlor',\n",
    "    'butorphic',\n",
    "    'tuzistra',\n",
    "    'methadose',\n",
    "    'tylagesic',\n",
    "    'zomorph',\n",
    "    'opana',\n",
    "    'depodur',\n",
    "    'ibudone',\n",
    "    'pethilorfan',\n",
    "    'vanacet',\n",
    "    'hyco-pap',\n",
    "    'aceon',\n",
    "    'hycodan',\n",
    "    'hydrogesic',\n",
    "    'primlev',\n",
    "    'zydone',\n",
    "    'co-gesic',\n",
    "    'phenco-care',\n",
    "    'tussionex',\n",
    "    'sublimaze',\n",
    "    'msir',\n",
    "    'm-eslon',\n",
    "    'hydropane',\n",
    "    'magnacet',\n",
    "    'onsolis',\n",
    "    'vendone',\n",
    "    'eth-oxydose',\n",
    "    'hydromet',\n",
    "    'm-oxy',\n",
    "    'pyregesic',\n",
    "    'oxecta',\n",
    "    'm-phen',\n",
    "    'vidone',\n",
    "    'margesic-h',\n",
    "    'codrix',\n",
    "    'hy-phen',\n",
    "    'tussigon',\n",
    "    'zamicet',\n",
    "    'ascomp',\n",
    "    'rms',\n",
    "    'oxyrapid',\n",
    "    'duramorph',\n",
    "    'hycomed',\n",
    "    'endocodone',\n",
    "    'guai-co',\n",
    "    'conzip',\n",
    "    'ugesic',\n",
    "    'rybix',\n",
    "    'stagesic',\n",
    "    'zolvit',\n",
    "    'brontex',\n",
    "    'codafen',\n",
    "    'oxydose',\n",
    "    'vicoprofen',\n",
    "    'ultracet',\n",
    "    'panacet',\n",
    "    'hycet',\n",
    "    'zyfrel',\n",
    "    'methex',\n",
    "    'hydrostat',\n",
    "    'duoneb',\n",
    "    't-gesic',\n",
    "    'cheratussin',\n",
    "    'tramalgin',\n",
    "    'percolone',\n",
    "    'polygesic',\n",
    "    'allay',\n",
    "    'oxyfast',\n",
    "    'buprenex',\n",
    "    'dolagesic',\n",
    "    'tylox',\n",
    "    'oxaydo',\n",
    "    'hydrocet',\n",
    "    'talacen',\n",
    "    'l-dromoran',\n",
    "    'fentora',\n",
    "    'alprazolam',\n",
    "    'chlordiazepoxide',\n",
    "    'clonazepam',\n",
    "    'diazepam',\n",
    "    'estazolam',\n",
    "    'flurazepam',\n",
    "    'lorazepam',\n",
    "    'oxazepam',\n",
    "    'temazepam',\n",
    "    'triazolam',\n",
    "    'clobazam',\n",
    "    'clorazepate',\n",
    "    'quazepam',\n",
    "    'calprazolam',\n",
    "    'niravam',\n",
    "    'xanax',\n",
    "    'chlordinium',\n",
    "    'clindex',\n",
    "    'h-tran',\n",
    "    'librax',\n",
    "    'libritabs',\n",
    "    'librium',\n",
    "    'limbitrol',\n",
    "    'mitran',\n",
    "    'poxi',\n",
    "    'tropium',\n",
    "    'ceberclon',\n",
    "    'klonopin',\n",
    "    'rivotril',\n",
    "    'valpax',\n",
    "    'alupram',\n",
    "    'atensine',\n",
    "    'd-val',\n",
    "    'dialar',\n",
    "    'diastat',\n",
    "    'diazemuls',\n",
    "    'dizac',\n",
    "    'evacalm',\n",
    "    'rimapam',\n",
    "    'stesolid',\n",
    "    'tensium',\n",
    "    'valicot',\n",
    "    'valium',\n",
    "    'zetran',\n",
    "    'prosom',\n",
    "    'dalmane',\n",
    "    'almazine',\n",
    "    'ativan',\n",
    "    'serax',\n",
    "    'restoril',\n",
    "    'halcion',\n",
    "    'frisium',\n",
    "    'onfi',\n",
    "    'gen-xene',\n",
    "    'tranxene',\n",
    "    'doral',\n",
    "    'asenapine',\n",
    "    'clozapine',\n",
    "    'risperidone',\n",
    "    'aripiprazole',\n",
    "    'brexpiprazole',\n",
    "    'cariprazine',\n",
    "    'iloperidone',\n",
    "    'lurasidone',\n",
    "    'olanzapine',\n",
    "    'paliperidone',\n",
    "    'pimavanserin',\n",
    "    'quetiapine',\n",
    "    'ziprasidone',\n",
    "    'saphris',\n",
    "    'clozaril',\n",
    "    'fazaclo',\n",
    "    'versacloz',\n",
    "    'risperdal',\n",
    "    'abilify',\n",
    "    'aristada',\n",
    "    'rexulti',\n",
    "    'vraylar',\n",
    "    'fanapt',\n",
    "    'latuda',\n",
    "    'symbyax',\n",
    "    'zyprexa',\n",
    "    'invega',\n",
    "    'nuplazid',\n",
    "    'seroquel',\n",
    "    'geodon',\n",
    "    'amphetamine',\n",
    "    'dextroamphetamine',\n",
    "    'doxapram',\n",
    "    'lisdexamfetamine',\n",
    "    'methamphetamine',\n",
    "    'methylphenidate',\n",
    "    'tropicamide',\n",
    "    'armodafinil',\n",
    "    'dexmethylphenidate',\n",
    "    'modafinil',\n",
    "    'p-hydroxyamphetamine',\n",
    "    'adderall',\n",
    "    'adderall-xr',\n",
    "    'evekeo',\n",
    "    'mydayis',\n",
    "    'dexedrine',\n",
    "    'dextrostat',\n",
    "    'durophet',\n",
    "    'liquadd',\n",
    "    'procentra',\n",
    "    'zenzedi',\n",
    "    'dopram',\n",
    "    'respiram',\n",
    "    'vyvanse',\n",
    "    'desoxyn',\n",
    "    'aptensio',\n",
    "    'concerta',\n",
    "    'metadate',\n",
    "    'methylin',\n",
    "    'quillivant',\n",
    "    'ritalin',\n",
    "    'ritalin-sr',\n",
    "    'paremyd',\n",
    "    'nuvigil',\n",
    "    'focalin',\n",
    "    'aller-tec',\n",
    "    'provigil',\n",
    "    }\n",
    "\n",
    "drug_rex = \"(\" + '|'.format(drugs) + \")\"\n",
    "df_train['text'] = df_train['text'].map(str)\n",
    "\n",
    "df_drugs = df_train[df_train.text.map(lambda x: re.search(drug_rex, x.lower()) is not None)]\n",
    "df_drugs.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>groundtruth</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>correct?</th>\n",
       "      <th>methex</th>\n",
       "      <th>oxyfast</th>\n",
       "      <th>carisoprodol</th>\n",
       "      <th>remifentanil</th>\n",
       "      <th>torbugesic</th>\n",
       "      <th>...</th>\n",
       "      <th>valpax</th>\n",
       "      <th>temazepam</th>\n",
       "      <th>procentra</th>\n",
       "      <th>anexsia</th>\n",
       "      <th>stagesic</th>\n",
       "      <th>naloxone</th>\n",
       "      <th>duocet</th>\n",
       "      <th>vyvanse</th>\n",
       "      <th>methadone</th>\n",
       "      <th>hy-phen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1948</th>\n",
       "      <td>oxycodone is a wonderful pain medication lmao. #thanksdoc</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3091</th>\n",
       "      <td>They gave me hydrocodone for my foot lol</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>_U not just fake xanax popped in scripted series either...but also real xanax being popped... those housewives love their xanax</td>\n",
       "      <td>0</td>\n",
       "      <td>m</td>\n",
       "      <td>a</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                 text  \\\n",
       "1948  oxycodone is a wonderful pain medication lmao. #thanksdoc                                                                         \n",
       "3091  They gave me hydrocodone for my foot lol                                                                                          \n",
       "4886  _U not just fake xanax popped in scripted series either...but also real xanax being popped... those housewives love their xanax   \n",
       "\n",
       "      label groundtruth predicted_class  correct?  methex  oxyfast  \\\n",
       "1948  0      c           a               False     0       0         \n",
       "3091  0      c           a               False     0       0         \n",
       "4886  0      m           a               False     0       0         \n",
       "\n",
       "      carisoprodol  remifentanil  torbugesic  ...  valpax  temazepam  \\\n",
       "1948  0             0             0           ...  0       0           \n",
       "3091  0             0             0           ...  0       0           \n",
       "4886  0             0             0           ...  0       0           \n",
       "\n",
       "      procentra  anexsia  stagesic  naloxone  duocet  vyvanse  methadone  \\\n",
       "1948  0          0        0         0         0       0        0           \n",
       "3091  0          0        0         0         0       0        0           \n",
       "4886  0          0        0         0         0       0        0           \n",
       "\n",
       "      hy-phen  \n",
       "1948  0        \n",
       "3091  0        \n",
       "4886  0        \n",
       "\n",
       "[3 rows x 301 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for d in drugs:\n",
    "    df_drugs[d] = df_train.text.map(lambda x: 1 if d in x.lower() else 0)\n",
    "    \n",
    "df_drugs.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xanax            2124\n",
       "adderall         1969\n",
       "morphine         1322\n",
       "valium           846 \n",
       "tramadol         577 \n",
       "methadone        415 \n",
       "oxycodone        340 \n",
       "oxycontin        325 \n",
       "vyvanse          300 \n",
       "hydrocodone      256 \n",
       "seroquel         232 \n",
       "ativan           229 \n",
       "klonopin         216 \n",
       "suboxone         195 \n",
       "diazepam         191 \n",
       "codeine          138 \n",
       "abilify          100 \n",
       "quetiapine       83  \n",
       "lorazepam        70  \n",
       "fentanyl         66  \n",
       "clonazepam       63  \n",
       "percocet         60  \n",
       "cocet            60  \n",
       "alprazolam       48  \n",
       "olanzapine       45  \n",
       "zyprexa          42  \n",
       "buprenorphine    40  \n",
       "vicodin          38  \n",
       "ritalin          35  \n",
       "rms              29  \n",
       "risperidone      26  \n",
       "caffeine         24  \n",
       "risperdal        23  \n",
       "ibuprofen        23  \n",
       "amphetamine      22  \n",
       "tylenol          21  \n",
       "dilaudid         19  \n",
       "norco            18  \n",
       "aripiprazole     16  \n",
       "onfi             10  \n",
       "geodon           10  \n",
       "dolophine        9   \n",
       "promethazine     9   \n",
       "aspirin          8   \n",
       "acetaminophen    8   \n",
       "temazepam        8   \n",
       "subutex          7   \n",
       "saphris          7   \n",
       "lortab           6   \n",
       "latuda           6   \n",
       "naloxone         6   \n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_drug_mentions = df_drugs.drop(columns=['text', 'label', 'groundtruth', 'predicted_class', 'correct?'])\n",
    "\n",
    "df_drug_mentions_sum = df_drug_mentions.sum().sort_values(ascending=False)\n",
    "\n",
    "df_drug_mentions_sum[df_drug_mentions_sum > 5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
